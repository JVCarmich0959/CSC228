{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVCarmich0959/CSC228/blob/main/Jacquelyn's_Copy_of_CSC228_Lesson04_IntentClassification_with_TFIDF_ATIS_DataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxmLYMY7u-Sl"
      },
      "outputs": [],
      "source": [
        "# Intent Classification using TF-IDF with the ATIS Dataset. \n",
        "#\n",
        "# Uses Libraries:  sklearn\n",
        "# Runtime:  Google CoLab (cpu)\n",
        "#\n",
        "# Owner:  Lorrie Tomek\n",
        "# \n",
        "# Data: \n",
        "# The data for ATIS intent classification was downloaded from kaggle to \n",
        "# my personal google drive for this course.  The URLs for downloading are\n",
        "# given in the notebook code below.  \n",
        "#\n",
        "# This data should not be shared outside of this course.  \n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the ATIS Dataset? \n",
        "\n",
        "The Airline Travel Information System (ATIS) dataset is often used as a benchmark dataset for intent classification in natural language processing. The dataset consists of a collection of spoken and written queries from users looking to book a flight, along with their corresponding intent labels. The intent labels in the dataset include information such as flight departure and arrival times, flight availability, and pricing. The ATIS dataset is commonly used to train and evaluate models for natural language understanding and intent classification.\n",
        "\n",
        "The ATIS (Airline Travel Information System) dataset is often distributed in a tab-separated format (.tsv) and it typically includes the following columns:\n",
        "\n",
        "- Sentence #: a unique identifier for each sentence in the dataset.\n",
        "- Utterance: the spoken or written text input from the user, which represents their request or query related to airline travel information such as flight departure and arrival times, flight availability, and pricing.\n",
        "- Intent: the corresponding label that indicates the intent behind the utterance. The intents in the ATIS dataset include information such as flight booking, flight cancellation, and flight information queries."
      ],
      "metadata": {
        "id": "2-vak-LIhMIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Where can we find the ATIS Dataset?\n",
        "\n",
        "The ATIS dataset can be downloaded from the official website of the dataset, which is the Linguistic Data Consortium (LDC) website.  However, this would require creating an account on that website to allow a download of the dataset.  \n",
        "\n",
        "The dataset (or a subset of it) can often be found on github.  If you search for \"atis datasset\" on github you will see several links.  Here's one I found. \n",
        "\n",
        "There is an intent/utterance dataset here: \n",
        "https://raw.githubusercontent.com/nawaz-kmr/Airline-Travel-Information-System-ATIS-Text-Analysis/nawaz-kmr/atis_intents.csv\n",
        "\n",
        "It used to be available at https://github.com/yvchen/JointSLU, but I did not find the csv there any more.  (I did find .iob files where are used for Entity Recognition training)."
      ],
      "metadata": {
        "id": "HR48rdmFvSrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial on Intent Classification using TF-IDF Features with the ATIS Dataset\n",
        "\n",
        "Start by installing the necessary libraries, such as scikit-learn and pandas.\n",
        "\n",
        "Download the ATIS dataset from a reliable source (such as https://github.com/yvchen/JointSLU).\n",
        "\n",
        "Load the dataset into a pandas DataFrame. The dataset should contain two columns: \"text\" and \"intent\". The \"text\" column contains the conversation utterances, and the \"intent\" column contains the annotated intent labels.\n",
        "\n",
        "Pre-process the text data. This may involve steps such as lowercasing, tokenization, and removing stop words.\n",
        "\n",
        "Split the dataset into training and test sets.\n",
        "\n",
        "Calculate the TF-IDF scores for each word in the training set.\n",
        "\n",
        "Use the TF-IDF scores as features to train a machine learning model, such as a support vector machine (SVM) or a random forest classifier.\n",
        "\n",
        "Evaluate the performance of the trained model on the test set.\n",
        "\n",
        "Use the trained model to predict the intent of new, unseen text data."
      ],
      "metadata": {
        "id": "qaxLUSTBu_rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and/or load needed libraries\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from pprint import pprint\n",
        "import requests\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "sxIhW9lv-JJk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The above code imports several libraries that will be used in the program:\n",
        "\n",
        "1. \"pandas\" is a library used for data analysis and manipulation. It is imported and aliased as \"pd\".\n",
        "\n",
        "2. \"sklearn\" is a library for machine learning in Python. It is imported without an alias.\n",
        "\n",
        "3. \"pprint\" is a library for pretty-printing data structures. It is imported from the \"pprint\" module.\n",
        "\n",
        "4. \"requests\" is a library for sending HTTP requests. It is imported from the \"requests\" module.\n",
        "\n",
        "5. \"StringIO\" is a library for working with string data as files or streams. It is imported from the \"io\" module."
      ],
      "metadata": {
        "id": "a_SjHQUEiCVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the data is no longer in JointSLU, this has been downlaoded originally from kaggle.  It should not be shared outside of this course, but can be downloaded from kaggle by signing up."
      ],
      "metadata": {
        "id": "yKMb_LTO_yQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# atis_intent.csv\n",
        "file_id = '1QU3YH0hfbC4Swq5Rs-zIWfHANJjOVJET'\n",
        "dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
        "url = requests.get(dwn_url).text\n",
        "csv_raw = StringIO(url)"
      ],
      "metadata": {
        "id": "FVkVVYv092x3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code is downloading a file from Google Drive and converting its contents into a string:\n",
        "\n",
        "1. The file to be downloaded is identified by its Google Drive file ID, stored in the variable \"file_id\".\n",
        "\n",
        "2. The download URL is constructed by concatenating the Google Drive URL with the file ID, stored in the variable \"dwn_url\".\n",
        "\n",
        "3. The \"requests\" library is used to send a GET request to the download URL, and the response text is stored in a variable \"url\".\n",
        "\n",
        "4. The contents of the file are converted into a string and stored in a \"StringIO\" object, \"csv_raw\". The \"StringIO\" object allows the string to be treated as a file-like object, so it can be used in functions that normally work with files."
      ],
      "metadata": {
        "id": "Xxht7lP3ibUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ATIS intents dataset into a pandas DataFrame\n",
        "# The column names are not in the first row, so we can set them on read_csv using names\n",
        "df = pd.read_csv(csv_raw, names = ['intent', 'utterance'])"
      ],
      "metadata": {
        "id": "3b2Zt-Xzv-l7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code loads the contents of the file, stored as a \"StringIO\" object in the variable \"csv_raw\", into a pandas DataFrame:\n",
        "\n",
        "1. The \"read_csv\" function from the \"pandas\" library is used to read the contents of the \"csv_raw\" object and store the resulting DataFrame in the variable \"df\".\n",
        "\n",
        "2. The \"names\" parameter is set to a list of column names to be used for the DataFrame. In this case, the columns are named \"intent\" and \"utterance\".\n",
        "\n",
        "3. This allows the data to be stored in a structured format, making it easier to manipulate and analyze.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "44sUEW9yjBRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the column names\n",
        "print(f\"columns: {df.columns}\")\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Print size of the dataframe\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fvZc-ctD_9m",
        "outputId": "856c1b9f-d3b5-4d99-9e7d-18aa979ef4a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns: Index(['intent', 'utterance', 'utterance_text'], dtype='object')\n",
            "             intent                                          utterance  \\\n",
            "0       atis_flight   i want to fly from boston at 838 am and arriv...   \n",
            "1       atis_flight   what flights are available from pittsburgh to...   \n",
            "2  atis_flight_time   what is the arrival time in san francisco for...   \n",
            "3      atis_airfare            cheapest airfare from tacoma to orlando   \n",
            "4      atis_airfare   round trip fares from pittsburgh to philadelp...   \n",
            "\n",
            "                                      utterance_text  \n",
            "0     want fly boston 838 arrive denver 1110 morning  \n",
            "1  flights available pittsburgh baltimore thursda...  \n",
            "2  arrival time san francisco 755 flight leaving ...  \n",
            "3                    cheapest airfare tacoma orlando  \n",
            "4  round trip fares pittsburgh philadelphia 1000 ...  \n",
            "(4978, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code prints some information about the \"df\" DataFrame:\n",
        "\n",
        "1. The first line uses an f-string to print the column names of the DataFrame, which are stored in the \"columns\" attribute of \"df\".\n",
        "\n",
        "2. The second line uses the \"head\" method of the DataFrame to print the first 5 rows of the DataFrame.\n",
        "\n",
        "3. The third line prints the dimensions of the DataFrame using the \"shape\" attribute of \"df\". The \"shape\" attribute returns a tuple of the number of rows and columns in the DataFrame.\n",
        "\n",
        "**These lines provide an overview of the contents and structure of the DataFrame, helping to ensure that it was loaded correctly and to get a feel for the data.**"
      ],
      "metadata": {
        "id": "2osOUIXEjclK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Data"
      ],
      "metadata": {
        "id": "KUEOcIriBkmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are all possible unique intent strings?\n",
        "set(df['intent'].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kDpFy9XBrsm",
        "outputId": "cc852a72-87a1-4cd2-8817-2aa2a04c08b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'atis_abbreviation',\n",
              " 'atis_aircraft',\n",
              " 'atis_aircraft#atis_flight#atis_flight_no',\n",
              " 'atis_airfare',\n",
              " 'atis_airfare#atis_flight_time',\n",
              " 'atis_airline',\n",
              " 'atis_airline#atis_flight_no',\n",
              " 'atis_airport',\n",
              " 'atis_capacity',\n",
              " 'atis_cheapest',\n",
              " 'atis_city',\n",
              " 'atis_distance',\n",
              " 'atis_flight',\n",
              " 'atis_flight#atis_airfare',\n",
              " 'atis_flight_no',\n",
              " 'atis_flight_time',\n",
              " 'atis_ground_fare',\n",
              " 'atis_ground_service',\n",
              " 'atis_ground_service#atis_ground_fare',\n",
              " 'atis_meal',\n",
              " 'atis_quantity',\n",
              " 'atis_restriction'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code is setting a dataframe (df) column called 'intent' as a list of unique values. This list can be used to determine all the possible unique intent strings that are present in the dataframe."
      ],
      "metadata": {
        "id": "eisMzVTOlHww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Utterance Text"
      ],
      "metadata": {
        "id": "SdY6hDb4B5b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# downloads needed from nltk\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0xQyDKCGt6v",
        "outputId": "73c29b07-ad62-4342-963d-d16dfa37c582"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the NLTK library and the stopwords corpus from NLTK. It then downloads the punkt and stopwords packages from the NLTK library, which are needed for the code that follows. \n",
        "\n",
        "This code is helpful for preprocessing because it will allow for the removal of stopwords from a text. Stopwords are common words that are usually filtered out before natural language processing, as they don't carry much meaning and can interfere with obtaining meaningful results from text analysis."
      ],
      "metadata": {
        "id": "KgnXZBSulbxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[:10] # looking at our 2 column dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pKjrMdrEHJnG",
        "outputId": "a95624b4-3bea-4087-f98e-8229de61428b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                intent                                          utterance\n",
              "0          atis_flight   i want to fly from boston at 838 am and arriv...\n",
              "1          atis_flight   what flights are available from pittsburgh to...\n",
              "2     atis_flight_time   what is the arrival time in san francisco for...\n",
              "3         atis_airfare            cheapest airfare from tacoma to orlando\n",
              "4         atis_airfare   round trip fares from pittsburgh to philadelp...\n",
              "5          atis_flight   i need a flight tomorrow from columbus to min...\n",
              "6        atis_aircraft   what kind of aircraft is used on a flight fro...\n",
              "7          atis_flight   show me the flights from pittsburgh to los an...\n",
              "8          atis_flight              all flights from boston to washington\n",
              "9  atis_ground_service   what kind of ground transportation is availab..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c31c242-6f64-48ef-a302-9ac8f21539b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i need a flight tomorrow from columbus to min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>atis_aircraft</td>\n",
              "      <td>what kind of aircraft is used on a flight fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>show me the flights from pittsburgh to los an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>all flights from boston to washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>atis_ground_service</td>\n",
              "      <td>what kind of ground transportation is availab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c31c242-6f64-48ef-a302-9ac8f21539b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c31c242-6f64-48ef-a302-9ac8f21539b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c31c242-6f64-48ef-a302-9ac8f21539b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the Text Data by lowercasing, tokenization, and removing stopwords\n",
        "# We will name the column utterance_text after doing the preprocessing\n",
        "\n",
        "# Lowercase the utterance\n",
        "df[\"utterance_text\"] = df[\"utterance\"].str.lower() # re-assigning the utterance column to the utterance_text column\n",
        "\n",
        "# Tokenize the text and remove stopwords\n",
        "df[\"utterance_text\"] = df[\"utterance_text\"].apply(nltk.word_tokenize)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "df[\"utterance_text\"] = df[\"utterance_text\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "df[\"utterance_text\"] = df[\"utterance_text\"].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "Vx1lxywbvYxG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code is helping with preprocessing the text data by :**\n",
        "\n",
        "\n",
        "1. The code lowercases the text by using the str.lower() method on the \"utterance\" column and stores the result in a new column called \"utterance_text\". \n",
        "\n",
        "2. It then tokenizes the text by using the word_tokenize method on the \"utterance_text\" column. \n",
        "\n",
        "3. it removes stopwords by using the set method on the stopwords library, comparing each word in the \"utterance_text\" column to the set of stopwords, and then joining the remaining words back together into a string. All of these steps help make the text data more manageable and easier to analyze."
      ],
      "metadata": {
        "id": "lI65ST3Al49s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[:5] # looking at our new columns and the cleaned \"utterance_text\" column"
      ],
      "metadata": {
        "id": "4jAb1uE2Hh7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "16e2c5cb-6e4d-4e2e-ea94-b3ee13ad6f5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             intent                                          utterance  \\\n",
              "0       atis_flight   i want to fly from boston at 838 am and arriv...   \n",
              "1       atis_flight   what flights are available from pittsburgh to...   \n",
              "2  atis_flight_time   what is the arrival time in san francisco for...   \n",
              "3      atis_airfare            cheapest airfare from tacoma to orlando   \n",
              "4      atis_airfare   round trip fares from pittsburgh to philadelp...   \n",
              "\n",
              "                                      utterance_text  \n",
              "0     want fly boston 838 arrive denver 1110 morning  \n",
              "1  flights available pittsburgh baltimore thursda...  \n",
              "2  arrival time san francisco 755 flight leaving ...  \n",
              "3                    cheapest airfare tacoma orlando  \n",
              "4  round trip fares pittsburgh philadelphia 1000 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22976fbb-f0f1-4a28-a3be-c30ef3c81908\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>utterance</th>\n",
              "      <th>utterance_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
              "      <td>want fly boston 838 arrive denver 1110 morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "      <td>flights available pittsburgh baltimore thursda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "      <td>arrival time san francisco 755 flight leaving ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "      <td>cheapest airfare tacoma orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "      <td>round trip fares pittsburgh philadelphia 1000 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22976fbb-f0f1-4a28-a3be-c30ef3c81908')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22976fbb-f0f1-4a28-a3be-c30ef3c81908 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22976fbb-f0f1-4a28-a3be-c30ef3c81908');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data into Train and Test"
      ],
      "metadata": {
        "id": "jj_lxwQaBho2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Dataset into Training and Testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"utterance_text\"], df[\"intent\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "c9-r2y0ow2if"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is using the scikit-learn train_test_split() function to :\n",
        "\n",
        "1. split a given dataset into training and test sets. The variables X_train and X_test represent the training and test data for the independent variables, while y_train and y_test represent the training and test data for the dependent variable.\n",
        "\n",
        "2.  The test_size argument is set to 0.2, indicating that 20% of the data will be used for testing and 80% for training. The random_state argument is set to 42, thus the data will be randomly split into the training and test set"
      ],
      "metadata": {
        "id": "FlAoO39grRtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look the results of the split\n",
        "print(f\"X_train.shape = {X_train.shape}\")\n",
        "print(f\"X_test.shape = {X_test.shape}\")\n",
        "print(f\"y_train.shape = {y_train.shape}\")\n",
        "print(f\"y_test.shape = {y_test.shape}\")"
      ],
      "metadata": {
        "id": "0j-Nm6iTL4Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2cf2d0-5537-4d56-9964-b0db3c98b101"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape = (3982,)\n",
            "X_test.shape = (996,)\n",
            "y_train.shape = (3982,)\n",
            "y_test.shape = (996,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:5]) # exploring and looking at your training sets are a good way to get a feel for how your model is being trained and tested\n",
        "\n",
        "# here we take a look at the utterances that are in the testing data."
      ],
      "metadata": {
        "id": "4xI78sYOMF-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5169bfb-3f4e-4ba8-9479-fcff1c186cd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3414    american airlines flight denver san francisco ...\n",
            "1499    twa flight leaving early morning san francisco...\n",
            "4003    show flights atlanta washington dc wednesday n...\n",
            "3866    types aircraft get first class ticket philadel...\n",
            "422                                        many seats 100\n",
            "Name: utterance_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:5])  # and here are the intents!"
      ],
      "metadata": {
        "id": "dygaAyB6MNV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6065c00-d1d7-4e95-c97b-3408fa00af7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3414      atis_flight\n",
            "1499      atis_flight\n",
            "4003      atis_flight\n",
            "3866    atis_aircraft\n",
            "422     atis_capacity\n",
            "Name: intent, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train TF-IDF Vectorizer\n",
        "\n",
        "This code is calculating the TF-IDF score for each word in the training set. \n",
        "\n",
        "1. It starts by importing the TfidfVectorizer from the scikit-learn library. \n",
        "\n",
        "2. It then initializes the TfidfVectorizer and calculates the TF-IDF scores for the training set. \n",
        "\n",
        "3. Finally, it prints the shape of the training set."
      ],
      "metadata": {
        "id": "ZYrFUC7LCC1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the TF-IDF score for each word in the training set\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Calculate the TF-IDF scores for the training set\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Print the shape of the training set\n",
        "print(X_train_tfidf.shape)"
      ],
      "metadata": {
        "id": "1FSMp4BTw7Dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e898df98-fffc-4312-dda5-237d17961687"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3982, 724)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the TF-IDF vectors\n",
        "# X_train_tfidf is a 2 dimentional matrix of floating point numbers\n",
        "# Each row represents the TF-IDF of one utterance\n",
        "# It doesn't look like a matrix, because most of the matrix elements are zero, and it is stored in a sparce memory representation\n",
        "print(X_train_tfidf[:1])"
      ],
      "metadata": {
        "id": "PKzF9VvHMXGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94707668-67ba-41ad-f066-7fcdcf1fa8f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 459)\t0.38911248129023623\n",
            "  (0, 281)\t0.5061299392133041\n",
            "  (0, 328)\t0.28014363567453604\n",
            "  (0, 562)\t0.26574624881946984\n",
            "  (0, 253)\t0.26355606460712255\n",
            "  (0, 317)\t0.2503194208876888\n",
            "  (0, 138)\t0.3493304655633338\n",
            "  (0, 147)\t0.4349356852801214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Machine Learning Model\n",
        "\n",
        "This code is creating and fitting an SVM classifier using TF-IDF scores as features:\n",
        "\n",
        "1.  The SVM classifier is initialized using the \"linear\" kernel.\n",
        "\n",
        "2. Then it is fit to the training data, which consists of the TF-IDF scores (X_train_tfidf) and the training labels (y_train).\n",
        "\n",
        "**SVM classifiers are helpful because they can be used for both classification and regression tasks.** They are also effective in high-dimensional spaces and can create non-linear decision boundaries. Additionally, they are more robust than other classifiers, meaning that **they are less likely to overfit the data.**"
      ],
      "metadata": {
        "id": "STpSthX1CJ1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the TF-IDF scores as features to train a machine learning model selecting a classifier\n",
        "# Here we are using a support vector machine (SVM) but we could use other types of classifiers (e.g., random forest classifier)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "clf = SVC(kernel=\"linear\")\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "clf.fit(X_train_tfidf, y_train)\n"
      ],
      "metadata": {
        "id": "KFb_4G60xIAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d858235-536f-480d-b760-0aa95132d9a5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Performance of a Trained Model\n",
        "\n",
        "After training, we can evaluate the performance of the trained model on a test set (the test set not used for training).  \n",
        "\n",
        "Various evaluation metrics can be used such as accuracy, precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "ukoT8gebx3ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the TF-IDF scores for the test set\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "accuracy = sum(y_pred == y_test) / len(y_test)\n",
        "print(f\"Accuracy on the test set: {accuracy:.2f}\")\n",
        "\n",
        "# This score is very good!"
      ],
      "metadata": {
        "id": "H7EwUQA8xZzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ded30c8-128b-4515-ac20-554b6b75a50f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Explore this model to predict new intents on custom data:\n",
        "\n",
        "This code uses a trained machine learning model to predict the intent of a new piece of text. \n",
        "\n",
        "1. The new text is preprocessed in the same way as the training data, including lowercasing and tokenizing the text, removing stop words, and joining the remaining tokens back into a single string.\n",
        "\n",
        "2. The TF-IDF scores for the new text are calculated using the vectorizer, and the clf model is used to make a prediction on the intent of the text based on the TF-IDF scores.\n",
        "\n",
        "3. The prediction is printed to the console with the statement print(prediction). **Note that the prediction output will be a label or class assigned to the new text based on the intent classification model.**"
      ],
      "metadata": {
        "id": "xNBBcIIPu8s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to predict intents on custom data\n",
        "\n",
        "# Pre-process the text we are evaluating the same way we \n",
        "# preprocessed the training data\n",
        "\n",
        "# Define a new piece of text\n",
        "new_text = \"tickets?\"\n",
        "\n",
        "# Lower case\n",
        "new_text = new_text.lower()\n",
        "print(f\"STEP 1: {new_text}\") #passing it through the .lower() method\n",
        "\n",
        "new_text_tokens = nltk.word_tokenize(new_text) # tokenizing the text\n",
        "print(f\"STEP 2: {new_text_tokens}\")\n",
        "\n",
        "new_text_tokens = [word for word in new_text_tokens if word not in stop_words] # for every word in the new utterance that isn't in the stop words corpus print the tokenized text\n",
        "print(f\"STEP 3: {new_text_tokens}\")\n",
        "new_text = ''.join(new_text_tokens)\n",
        "\n",
        "# Calculate the TF-IDF scores for the new text\n",
        "new_text_tfidf = vectorizer.transform([new_text]) # fresh baby utterance is classified\n",
        "\n",
        "# Predict the label for the new text\n",
        "prediction = clf.predict(new_text_tfidf) # It's a boy!\n",
        "\n",
        "# Print the prediction\n",
        "print(prediction) # post to social media!"
      ],
      "metadata": {
        "id": "IBtI_2FyxgtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa53563-2196-47ca-d929-a27026809704"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: tickets?\n",
            "STEP 2: ['tickets', '?']\n",
            "STEP 3: ['tickets', '?']\n",
            "['atis_airfare']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# defining a function for the above code\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def predict_intent(text, vectorizer, clf, stop_words=None):\n",
        "    if stop_words is None:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "    \n",
        "    # Pre-process the text\n",
        "    text = text.lower()\n",
        "    text_tokens = nltk.word_tokenize(text)\n",
        "    text_tokens = [word for word in text_tokens if word not in stop_words]\n",
        "    text = ' '.join(text_tokens)\n",
        "    \n",
        "    # Calculate the TF-IDF scores for the text\n",
        "    text_tfidf = vectorizer.transform([text])\n",
        "    \n",
        "    # Predict the label for the text\n",
        "    prediction = clf.predict(text_tfidf)\n",
        "    \n",
        "    return prediction[0]\n",
        "\n",
        "\n",
        "\n",
        "predict_intent(\"How many bags can I carry?\", vectorizer, clf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G45IP7aowrlU",
        "outputId": "72080d12-326d-413e-b10b-dbc68a036ce0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'atis_quantity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Big Picture\n",
        "## Why is intent classification important in NLP?:\n",
        "\n",
        "Classifying intents in NLP is important because **it helps in understanding the goal** or purpose of a text message, whether it's a question, request, or statement. This information is crucial for building conversational AI systems, such as chatbots, virtual assistants, and customer service bots, which need to understand the intent behind a user's message in order to respond appropriately.\n",
        "\n",
        "Intent classification also **helps to improve the accuracy and efficiency** of NLP-based systems by reducing the number of potential interpretations for a given text message, and allowing the system to focus on a smaller set of potential responses. It also enables NLP systems to handle a wide range of user requests, even when the requests are phrased in different ways.\n",
        "\n",
        "In addition, intent classification can also be **used to improve user experience** by anticipating user needs, providing relevant information proactively, and personalizing the interaction!\n",
        "\n",
        "In this case the need for fast solutions to flight inquiry using the ATIS model is crucial. \n",
        "\n"
      ],
      "metadata": {
        "id": "vzK2xWYVzRwL"
      }
    }
  ]
}