{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVCarmich0959/CSC228/blob/main/Jacquelyn's_Copy_of_CSC228_Lesson05_First_NeuralNetwork_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W04WrwWgYDvT"
      },
      "outputs": [],
      "source": [
        "# Text Classification using Neural Networks\n",
        "# CNN Neural Network Architecture\n",
        "# Using Keras wrapper module in Tensorflow\n",
        "#\n",
        "# Owner:  Lorrie Tomek\n",
        "#\n",
        "# Uses Libraries:  keras, tensorflow\n",
        "# Runtime:  Google CoLab (cpu)\n",
        "# \n",
        "# Data: \n",
        "#\n",
        "# Reference:  https://realpython.com/python-keras-text-classification/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "# import python libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "metadata": {
        "id": "Jrh0WsQCAKgA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Keras\n",
        "Keras was originally written as a wrapper layer, that could wrap different deep learning and neural network APIs including the lower layer APIs of Tensorflow.  \n",
        "\n",
        "Keras provides a simpler interface to build a neural network.  Keras was built by François Chollet, who in a book described it as: \n",
        "\n",
        "Keras is a model-level library, providing high-level building blocks for developing deep-learning models. It doesn’t handle low-level operations such as tensor (multi-dimensional vector) manipulation and differentiation. Instead, it relies on a specialized, well-optimized tensor library to do so, serving as the backend engine of Keras (Source)\n",
        "\n",
        "Keras is a great way to start experimenting with neural networks without having to implement every layer and piece on your own. For example Tensorflow is a great machine learning library, but you have to implement a lot of boilerplate code to have a model running.\n",
        "\n",
        "Today, Keras is a module that is part of Tensorflow 2.0"
      ],
      "metadata": {
        "id": "6RSaS-zYLSJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the keras package (actually not needed as it is preinstalled in Google Colab)\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vfMH1E0Y0rM",
        "outputId": "733049d1-08ab-4844-ca57-2696c7aea0af"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose and Download a Dataset\n",
        "\n",
        "I am using my previous dataset that I created using extracted comments from facebook regarding sentiments about the mall. I actually extended it will probably continue to expand this dataset for future use. I tried to add additional examples of positive and negative utterances that could help guid the classifier."
      ],
      "metadata": {
        "id": "3EVg8bTiVYJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in my data from the github repository to a data frame \n",
        "\n",
        "url = \"https://raw.githubusercontent.com/JVCarmich0959/CSC228/main/WUG_Mall_improvement.csv\"\n",
        "\n",
        "df = pd.read_csv(url, usecols=[0,1,2], encoding='latin-1')\n",
        "\n",
        "df = pd.concat([df, pd.read_csv(url, usecols=[0,1,2], encoding='latin-1')])\n",
        "print(df.iloc[100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmQ-mNxXWeN",
        "outputId": "f917210a-6c00-4601-b788-850cc0633017"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source                                               Facebook\n",
            "Label                                                       1\n",
            "Sentence    Thereâs always something fun to do at the mall.\n",
            "Name: 100, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EflylFBje5TG",
        "outputId": "cbb2419d-b514-40f8-ed39-a68ab46c223e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Source  Label                                           Sentence\n",
              "0  Facebook      0              Anything but another damn shoe store.\n",
              "1  Facebook      1  The mall is a joke. When I worked there 30+ ye...\n",
              "2  Facebook      1                                     A Spencerâs \n",
              "3  Facebook      1  Arcade for kids and teens that serves food whe...\n",
              "4  Facebook      1                      Dillards, Talbots, Chicoâs."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3668e2d-c15c-41c6-b62a-35741b5a020c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Label</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>0</td>\n",
              "      <td>Anything but another damn shoe store.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>1</td>\n",
              "      <td>The mall is a joke. When I worked there 30+ ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>1</td>\n",
              "      <td>A Spencerâs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>1</td>\n",
              "      <td>Arcade for kids and teens that serves food whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>1</td>\n",
              "      <td>Dillards, Talbots, Chicoâs.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3668e2d-c15c-41c6-b62a-35741b5a020c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3668e2d-c15c-41c6-b62a-35741b5a020c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3668e2d-c15c-41c6-b62a-35741b5a020c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filthy dirty data makes for a ill fitted machine so I went back and pre-processed a bit\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Tokenize words\n",
        "    words = text.split()\n",
        "    \n",
        "    # Remove stop words\n",
        "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "    \n",
        "    # Join words back into a single string\n",
        "    cleaned_text = \" \".join(words)\n",
        "    \n",
        "    return cleaned_text\n",
        "\n",
        "df[\"Sentence\"] = df[\"Sentence\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "print(df['Sentence']) # Now that'S what I call ITERABLE "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4nbKNfbgCfO",
        "outputId": "0e19b5b7-2afb-4a3a-e14b-c4ac2e4b5ad2"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                       anything another damn shoe store\n",
            "1      mall joke worked 30 years ago nice understand ...\n",
            "2                                            spencerâs\n",
            "3                       arcade kids teens serves food kw\n",
            "4                             dillards talbots chicoâs\n",
            "                             ...                        \n",
            "277    store organized wellstocked able find everythi...\n",
            "278    much fun shopping today canât wait wear new ...\n",
            "279        shopping center lively vibrant felt energized\n",
            "280    customer service fantastic went beyond help fi...\n",
            "281       impressed quality products know last long time\n",
            "Name: Sentence, Length: 564, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a dictionary called 'filepath_dict' with keys 'yelp', 'amazon', and 'imdb' and the respective file paths for each as the values.\n",
        "\n",
        "The code then creates an empty list 'df_list' which will store pandas dataframes for each of the files.\n",
        "\n",
        "Using a for loop, it iterates over the items in the 'filepath_dict' dictionary. For each iteration, it:\n",
        "\n",
        "1. Reads the file at the given path using the 'pd.read_csv' function, where the resulting data is stored in a pandas dataframe 'df'\n",
        "\n",
        "2. Adds a new column to the 'df' dataframe with the nae \"source\" and the value of the source (which is the key from the 'filepath_dict')\n",
        "\n",
        "3. Appends the resulting 'df' dataframe to the 'df_list' list\n",
        "\n",
        "After looping over al the files, it concatenates the dataframes in 'df_list' into a single dataframe 'df' using the 'pd.concat' function.\n",
        "\n",
        "Finally, it prints the first row (index 0) of the resulting dataframe using 'df.iloc[0]'."
      ],
      "metadata": {
        "id": "KkQAJtOd0G9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data into training and testing\n",
        "\n",
        "The code below is using the 'train_test_split' function from the 'sklearn.model_selection' module in scikit-learn. The function is used to split the data into training and testing sets.\n",
        "\n",
        "'df_yelp' is a sub-dataframe of 'df' that contains only the rows where the value of the 'sorce' column is equal to 'yelp'. The value of the 'sentence' column in 'df_yelp' are assigned to the 'sentences' variable and the values of the 'label' column are assigned to the 'y' variable.\n",
        "\n",
        "The 'train_test_split' function then splits the 'sentences' and 'y' arrays into four new arrays: 'sentences_train', 'sentences_test', 'y_train', and 'y_test.' The split is done with a ratio of 75% for the training set and 25% for the testing set(controlled by the 'test_size' parameter). The random state (controlled by the 'random_state'parameter). is set to 1000 to ensure **reproducibility** of the split.\n",
        "\n",
        "This is important because machine learning models are trained on a training set and evaluated on a testing set. The goal is to train the model on the training set and have it generalize well to new, unseen data represented by the testing set. By randomly splitting the data into training and testing sets, we can ensure that the model is not overfitting, which is when the model has memorized the training data instead of learning to generalize new data.\n"
      ],
      "metadata": {
        "id": "S1RwDHR6m1yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_facebook = df[df['Source'] == 'Facebook' ]\n",
        "sentences = df_facebook['Sentence'].values\n",
        "\n",
        "y = df_facebook['Label'].values\n",
        "\n",
        "# split the data into training and test sets\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
        "    sentences, y, test_size=0.2, random_state=1000)"
      ],
      "metadata": {
        "id": "_GKxpqOoakvU"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences_train[2]) # exploring my training set GOTTA LOVE GREENVILLE COMMENTERS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC-3dYiRglSZ",
        "outputId": "5a594e48-8174-41e1-fe96-4acd62afcd31"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "want see mall brings go greenville least three shootings mall every year mention want gangs hanging around causing trouble\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[2]) # looking at the sentiment of the selected utterance from training set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBbQjryRg4Ei",
        "outputId": "764b6327-dbb5-44bf-e983-507ef09678d3"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Use BoW to Vectorize our Sentences\n",
        "\n",
        "The code below is using:\n",
        "1. 'CountVectorizer' class from the 'sklearn.feature_extraction.text' module to convert text into numerical representations, a process known as vectorization. The vectorized representation of the text data will be used as input for a mahcine learning model.\n",
        "\n",
        "2. A 'CountVectorizer' object is created and named 'vectorizer'. The 'fit' method is then called on 'vectorizer' with the 'sentences_train' as input. This trains the 'CountVectorizer' object on the training data and creates a vocabulary of words that the vectorizer will use to vectorize the text.\n",
        "\n",
        "3. The 'transform method is called on the 'sentences_train' and 'sentences_test' to obtain the vectorized representations of the text data. The results are stored in the 'X_train' and 'X_test\" arrays, respectively.\n",
        "\n",
        "'CountVectorizer' is a method commonly used for text vectorization. It counts the number of occurences of each word in a text document and represents each document as a vector of word frequencies.\n",
        "\n",
        "Other vectorization methods include the **'TfidVectorizer'** which we learned earlier is an alternative to the 'CountVectorizer' that scales down the impact of words that occur frequently across many different documents. Another one we haven't touched on is **word embeddings**, which uses a neural network to learn a dense numerical representation for each word in a vocabulary and represents each document as a dense vector of word embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "yOlI8IVJnf8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train)\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test  = vectorizer.transform(sentences_test)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0T1hCuGna3V",
        "outputId": "545a24a5-4d8c-4781-8e9e-4ab7bddcfcfe"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<428x623 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2172 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Matrix\n",
        "\n",
        "The result of a sparse matrix from this code means that the vectorized representation of the text data is sstored in a sparse matrix. A sparse matrix is a matrix where most of the elements are zero, and it's stred in a compact format that only stores the non-zero elements.\n",
        "\n",
        "In text data, it's common to have many words that are not present in a given document, which results in a high proportion of zeros in the word frequency matrix. By using a sparse matrix representation, the memory usage and computation time can be signigicantly reduced compared to a dense matrix representation that scores all the zero elements. This sparse matrix can now be used as input for a machine learning model."
      ],
      "metadata": {
        "id": "u9WPUVHu4vbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's build our first Keras Neural Network Model\n",
        "\n",
        "This code creates a simple neural network model using the 'Sequential' class from the 'keras.models' module and the 'layers' module from the 'kera' library. The model consists of two dense layers, also known as fully connected layers.\n",
        "\n",
        "The first line of the code defines 'input_dim' as the number of features, which is obtained by accessing the second dimension of the 'X_train' array.\n",
        "\n",
        "The second line creates a new 'Sequential' object, which is a type of model in Keras that allows you to build a linear stack of layers.\n",
        "\n",
        "The third line adds the first dense layer to the model 'model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))'. The 'layers.Dense' constructor creates a dense laer with 10 units, an input dimension equal to 'input_dim' and a ReLU activation function. The ReLU activation function is commonly used in the hidden layers of neural networks and returns the input if it's positive, otherwise returns zero.\n",
        "\n",
        "The foruth line adds a second dense layer with 'model.add(laers.Dense(1, activation='sigmoid'))'. This layer has one unit and a sigmoid activation function. The sigmoid activation function is commonly used in the output layer of binary classification models and maps the input to values between 0 and 1, which can be interpreted as a probability.\n",
        "\n",
        "In this code, theneural network model is built using two dense layers, but other types of layers and more layers could be added to the model to create more complex models. The nuber of units and activation function sin the layers can be adjusted to optimize the performance of the model.\n"
      ],
      "metadata": {
        "id": "dUjO-5rUnLSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential() # start creating the sequential model \n",
        "\n",
        "# add one dense layer (don't worry about the 10)\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "\n",
        "# add a second dense layer\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "P8d696oQaH97"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the model architecture using the summary() method.\n",
        "\n",
        "The total number of trainable parameters is 17,161.\n",
        "\n",
        "The second layer receives all the inputs from the first layer, and has an additional one value that is output.\n",
        "\n",
        "The 'model.summary' function in Keras is an important tool for inspecting the architecture of a neural netowrk model. It providews a summary of the model's layers. the number of parameters in each layer, and the overall number of parameters in the model.\n",
        "\n",
        "By looking at the summary of the model's architecture, you can quickly check the number of layers and the number of parameters in each layer, which can give you an idea of the model's complexity and capacity. This information can help you to identify potential issues such as overfitting, underfitting, and poor generalization performance.\n",
        "\n",
        "You can also use the summary to check if the input shape of the model matches the expected input shape of your data, and to make sure that the output shape of the model matches the expected number of outputs for your task.\n",
        "\n",
        "Overall, the 'model.summary()' function is an important tool for understanding and debugging neural network models, and it's a good practice to use it regularly during the model development and training process."
      ],
      "metadata": {
        "id": "XxQAjPQiDAqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see the model architecture using the summary() method\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDHX7i9CuKu",
        "outputId": "586c3ee4-12fa-4033-8b5d-aecfcfd44102"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                6240      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,251\n",
            "Trainable params: 6,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the Model\n",
        "\n",
        "Before you can start with the training of the model, you need to configure the learning process. This is done with the .compile() method. The **'compile'** function is used to specify the loss function, optimization algorithm, and metrics to be used during training.\n",
        "\n",
        "1. **'loss' **: The loss function is used to evaluate how well the model is performing. The'binary_crossentropy' is a loss function used for binary classification problems, where the goal is to predict one of two outcomes.\n",
        "\n",
        "2. **'optimizer'**: The optimization algorithm is used to update the model weights to minimize the loss function. The 'adam' optimizer is a popular choice for many deep learning problems.\n",
        "\n",
        "3. **'metrics'**: The metrics are used to monitor the performance of the model during training and testing. In this case, the 'accuracy' metric is specified, which is a common metric for evaluating the accuacy of a binary classifier.\n",
        "\n",
        "Compiling the model is an important step in training a machine learning model as it **sets up the framework for the training process and defines how the model will be updated** based on the data it sees during training.\n"
      ],
      "metadata": {
        "id": "Oohog_Obn75G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eRzb0HLjaQgh"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj8HHe_ooTz2",
        "outputId": "81a9f1d7-1b18-4b03-96af-4b814021a890"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anything another damn shoe store',\n",
              "       'mall joke worked 30 years ago nice understand want much money spaces town needs kohls mall',\n",
              "       'spencerâ\\x80\\x99s', 'arcade kids teens serves food kw',\n",
              "       'dillards talbots chicoâ\\x80\\x99s'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the model using the fit() method.  We choose the number of epochs we want to train for, and provide both the training data, and validation data.  We set the batch size to 10, as that is the number of inputs that will be provided during each epoch.  The use of batches allows very large datasets (ones that cannot be stored in memory) to be used to train models.\n",
        "\n",
        "We assign the result to history, a variable that collects statistics on the model during the training process.\n",
        "\n",
        "If you have taken Machine Learning, and learned about hyperparameter tuning, some of the paramters on fit (like epochs) can be tuned as hyperparameters.  An epoch, is a complete iteration through the training data.  Epochs is the number of chances the model gets to determine the correct parameter values.\n",
        "\n",
        "When you run this cell, notice that the loss decreased and the accuracy increased."
      ],
      "metadata": {
        "id": "WDOSMSodEbXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "metadata": {
        "id": "MEL9f2V1Fv5W"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is being used to clear the internal state of the Keras library. This is useful when you want to start fresh, for example, if you are re-using the same Python session for multiple experiments and you want to ensure that the state of the previous experiment does not interere with the current one.\n",
        "\n",
        "** Note that calling 'clear_session' will release all GPU memory and reset the internal state of the library, so any existing models and variables will be lost. **"
      ],
      "metadata": {
        "id": "XNl2bgTP-J1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                     epochs=100,\n",
        "                     verbose=True,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ],
      "metadata": {
        "id": "Xda_9I7dYHUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2477f6-e5df-4031-c5e7-274437142f1d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - 1s 6ms/step - loss: 0.6849 - accuracy: 0.5421 - val_loss: 0.6669 - val_accuracy: 0.6481\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6379 - val_loss: 0.6409 - val_accuracy: 0.6759\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7033 - val_loss: 0.6077 - val_accuracy: 0.7685\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7850 - val_loss: 0.5684 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8481 - val_loss: 0.5241 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.9276 - val_loss: 0.4793 - val_accuracy: 0.8333\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.9579 - val_loss: 0.4381 - val_accuracy: 0.8981\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.9883 - val_loss: 0.3997 - val_accuracy: 0.9074\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.9953 - val_loss: 0.3676 - val_accuracy: 0.9074\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9953 - val_loss: 0.3391 - val_accuracy: 0.9352\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9977 - val_loss: 0.3158 - val_accuracy: 0.9352\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9977 - val_loss: 0.2951 - val_accuracy: 0.9352\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9977 - val_loss: 0.2779 - val_accuracy: 0.9444\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9977 - val_loss: 0.2634 - val_accuracy: 0.9352\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9977 - val_loss: 0.2485 - val_accuracy: 0.9444\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9444\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9444\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9444\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9444\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9444\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9444\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9444\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9444\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9444\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9444\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9444\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9444\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9444\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9444\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9444\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9444\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9444\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9444\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9444\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9444\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9444\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9444\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9444\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9444\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9444\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9444\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9444\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9444\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9444\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9444\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9444\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9444\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9444\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9444\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9444\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9444\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9444\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9444\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9444\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9444\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9444\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9444\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9444\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9444\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9444\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9444\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9444\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9444\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9444\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9444\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9444\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9444\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9444\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9444\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9444\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9444\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9444\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9444\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9444\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9444\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9444\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9444\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9444\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9444\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9444\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9444\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9444\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9444\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9444\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9444\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9444\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9444\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9444\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9444\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9444\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9444\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9444\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9444\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9444\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9444\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9444\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9444\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9444\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we are training the model using the 'fit' function on the 'model' object to fit the model to the training data 'X_train' and 'y_train'. I was able to improve the accuracy of the model to about 94% that's pretty good. Now we can see the power of quality data standardization👌🏾.\n",
        "\n",
        "* 'epochs': This parameter specifies the number of times the training data will be passed through the model. An epock is a complete iteration over the training data. In this case, the model will be trained for 100 epochs.\n",
        "\n",
        "* 'verbose': This parameter controls the verbosity mode during training. If 'verbose=True', training progress will be printed to the console. If 'verbose=False', training progress will not be printed.\n",
        "\n",
        "* 'validation_data': This parameter specifies the validation data('X_test' and 'y_test') that will be used to evaluate the model during trianing. The model's performance on the validation data will be used to monitor overfitting.\n",
        "\n",
        "* 'batch_size': This parmerter specifies the number of samples per gradient update. In this case, the batch size is set to 10, meaning that the model will be updated after every 10 samples.\n",
        "\n",
        "The 'fit' function returns a 'History' object, which is stored in the variable 'history'. This object contains information about the training process, such as the training loss, accuracy, and  validation loss and accuracy for each epoch. This information can be used to analyze the performance of the model and fine-tune its hyperparameters."
      ],
      "metadata": {
        "id": "AnMX_f_D-uvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZuBH2CUIE7k",
        "outputId": "4a8723d2-15cc-4560-f512-52450baf4469"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff1a070e50>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Accuracy of the Model\n",
        "\n",
        "We use the evaluate() method to test the model.  We can test the training data, and the test data.\n",
        "\n",
        "The 'evaluate' function is used to calculate the loss and accuracy of the model on the training data( 'X_train' and 'y_train') and testing data ('X_test' and 'y_test'). The performance of the model is calculated by comparing the model's predictions on the data with the true labels.\n",
        "\n",
        "The results of the evaluation are stored in the variables 'loss' and 'accuracy', which are then printed to the console. The accuracy of the model on the training data and testing data is printed, providing an estimate of how well the model will generalize to new, unseen data."
      ],
      "metadata": {
        "id": "F4_dw_CVo8QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLsknYMHo_VV",
        "outputId": "25279f76-9e1a-4689-bf41-bbe41b3fe327"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Testing Accuracy:  0.9444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the Loss and Accuracy of Training and Testing\n",
        "\n",
        "To make your life easier, you can use this little helper function to visualize the loss and accuracy for the training and testing data based on the History callback. This callback, which is automatically applied to each Keras model, records the loss and additional metrics that can be added in the .fit() method. In this case, we are only interested in the accuracy. This helper function employs the matplotlib plotting library:"
      ],
      "metadata": {
        "id": "q9iFns_FpLel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see the information kept in history from model training \n",
        "# has the following keys for each epoch\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpH7vKf0pr2J",
        "outputId": "78c41ad5-34eb-4cdd-a9ca-7fb8888598d2"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the plot_history function to see the overfitting.  Although additional training improved the accuracy of the training data, after some time it decreased the accuracy on the testing data."
      ],
      "metadata": {
        "id": "LpIDsxbOGHth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "sFClC9sFpIsS"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "H0aGL1k_p8Hl",
        "outputId": "9d5b24c9-dcaf-405b-9182-bd6068ed90d3"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAFACAYAAAC2ghqXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxU9f4/8NeZhX2RYVJEAb2jKEsuiBt5UQKXyoXuN6VbWrncNjO17N5yqW+L5dfklrdruWSaVvf6M9c0LTDNhNxDDRXBDRcUWWSHYeac3x8jkyMIAw4MM/N6Ph4+HpyZz/mc9wf08PYz78/nCJIkSSAiIiIicjAyawdARERERGQNTISJiIiIyCExESYiIiIih8REmIiIiIgcEhNhIiIiInJITISJiIiIyCExEW5me/bsgSAIuHz5cqPOEwQBX331VTNF1XJaYhwXLlyAIAjYt29fo647ZMgQTJky5Z6vv3r1aigUinvuh4jsB+/9vPdbkqViptqYCN8iCEK9fzp16tSkfqOiopCTkwN/f/9GnZeTk4PHHnusSdek5vn+Xb58GYIgYM+ePSavJyQk4MqVKxa9FhG1DN777Qvv/dRYnMa6JScnx/h1amoq/ud//gdHjx5F+/btAQByudykvVarhZOTU4P9Ojk5wc/Pr9HxNOUc+kNLfv9cXV3h6uraYtdrjaqrq6FUKq0dBlGj8d5vX3jvp8bijPAtfn5+xj8qlQoAcN999xlfa9u2Lf71r3/hiSeegLe3NyZMmAAAmDNnDkJCQuDm5oaAgAA8//zzKCoqMvZ758djNcdJSUmIjo6Gm5sbQkNDsWPHDpN47vx4RxAEfPrpp5gwYQI8PT3RsWNHfPDBBybn5OfnY+zYsXB3d0e7du0wb948PP3004iLi6t37A2Noebjn5SUFERERMDNzQ19+vTBoUOHTPrZvXs3evToARcXF/To0QO7d++u97qZmZkQBAGpqakmrx84cACCICAzMxMAsHjxYvTq1QseHh7w8/PD448/bvLLqy53fv8uXryIESNGwNXVFQEBAfjkk09qnfPNN9+gf//+8Pb2hlqtxiOPPIIzZ84Y3w8ICAAAxMTEmMwU1fXx2Pfff48+ffrA2dkZbdu2xYsvvoiysjLj+8888wzi4uKwfPlyBAUFwcvLC6NHj8b169frHVdDMQJAbm4uJk6ciHbt2sHFxQXdunXDF198YXz/7NmzeOyxx6BSqeDm5oYePXpg27Ztdx3LnbMhNX+Ht2/fjkGDBsHFxQWff/45CgsLMX78eAQGBsLV1RXdunVDYmIi7nx45bp169CnTx+4uLjA19cXDz30EAoLC7F69Wq0adMG5eXlJu3feecddO3atVY/RJbAez/v/bZw779TdXU1Xn/9dXTo0AFOTk4IDQ3FN998Y9Lm888/R0hICFxcXKBSqRAdHW38+1hcXIyJEyfCz88Pzs7OCAgIwCuvvNKoGOwFE+FGePvttxEVFYWjR4/ivffeA2D4H+Hy5ctx8uRJrF69Gnv27MHLL7/cYF+zZs3C7NmzcezYMfTv3x8JCQkoLCxs8PrR0dFIS0vDG2+8gdmzZ2PXrl3G9ydOnIhjx45h27Zt+Omnn3D58mVs3ry5wVjMGYMoinjjjTewePFiHD16FG3btsW4ceOg0+kAAFevXsXIkSPRp08fHD16FImJiZg+fXq91+3atSsGDhyItWvXmrz+5ZdfYuDAgejatavxtUWLFuHEiRPYtGkTsrOz8fjjjzc4rhqSJOHRRx9Ffn4+9uzZg++++w5bt27F0aNHTdpVVVVh7ty5OHr0KJKSkiCXy/HII49Aq9UCgLH9hg0bkJOTU+uXQY3jx49j9OjRiI6OxrFjx/Dll19i27ZteP75503aHTp0CLt378b27dvxww8/4MSJE5g1a1a9Y2koxoqKCgwePBjHjh3D119/jZMnT+KTTz6Bm5sbAODatWuIiorCzZs3sXXrVpw4cQLvvvsuZLLG3wpeffVV/OMf/8CpU6cwatQoVFVVITw8HJs3b8bJkycxb948vPXWW1i9erXxnFWrVmH8+PGIj4/H0aNHsXv3bowYMQJ6vR4JCQkQBAHr1683thdFEV988QWmTJkCQRAaHSORJfDez3s/YN17/51mz56NFStW4OOPP8bvv/+O8ePHY/z48ca/F0eOHMHzzz+PN954AxkZGfj555/x1FNPGc+vGe+WLVuQmZmJdevWISQkpFEx2A2Jatm9e7cEQLp06ZLxNQDSpEmTGjx348aNkpOTk6TX6+vsq+Z4w4YNxnOuXbsmAZB27txpcr21a9eaHE+bNs3kWt27d5def/11SZIk6cyZMxIAKTk52fi+VquVOnbsKMXGxjZm+LXGsGrVKgmAdOTIEWOb/fv3SwCk06dPS5IkSXPmzJECAwOl6upqY5vvvvuu1jju9Nlnn0k+Pj5SVVWVJEmSVFVVJalUKmnp0qV3Pefo0aMSAOny5cuSJEnS+fPnJQDSL7/8Ymxz+3WTkpIkAFJGRobx/dzcXMnFxUWaPHnyXa+Tn58vAZD27dsnSZIkXbp0SQIg7d6926TdqlWrJLlcbjweP3681LdvX5M2mzdvlgRBkC5cuCBJkiQ9/fTT0n333SdVVlYa2yxYsEDy8/O7azzmxPj5559Lzs7OJn93bzd37lypXbt2UmlpaZ3v3zkWSao97pq/w2vWrGkwvpdfflmKi4szHgcEBEhTp069a/tp06ZJDzzwgPF4586dklKplK5fv97gtYjuFe/9vPdLUuu89w8ePNgYc1lZmeTk5CQtWbLEpE18fLwUExMjSZLhZ+nl5SUVFRXV2d/o0aOlp59+ut5rOgrOCDdCv379ar22ceNGREdHw9/fHx4eHnjyySeh1Wpx7dq1evvq1auX8et27dpBLpc3+NHI7ecAgL+/v/GckydPAgAGDBhgfF+pVCIyMrL+QZk5BkEQ0LNnT5NrAzC5fr9+/Uw+Jho0aFCD105ISEB5ebnxo/lt27ahrKwMCQkJxjZ79uzB8OHDERAQAE9PT2O/Fy9ebLD/mtjUajWCg4ONr913333o1q2bSbu0tDQ8+uij6Ny5Mzw9PREYGNio69RIT09HdHS0yWuDBw+GJEnGnxMAdO/eHc7Ozsbj23+ed9NQjEeOHEFoaCg6duxY5/lHjhxBVFQU3N3dGzWmutz570EURSxYsAC9evWCWq2Gh4cHli5daowtNzcXly5dwrBhw+7a53PPPYeUlBScOnUKALBixQqMHj0abdu2ved4iZqK937e+83RnPf+22VlZUGr1dZ5rfT0dADA0KFD8ac//QmdO3fG448/juXLlyMvL8/Y9sUXX8S3336L8PBwTJ8+HTt27IAoio0ar71gItwIdyYPBw4cwNixYxEdHY1Nmzbh6NGjWLp0KQAYP1K5m7oWWzT0l/DOcwRBqHVOYz8+NncMMpnMZNFIzXXu9R+Oj48PRo0ahTVr1gAA1qxZg9GjR6NNmzYAgOzsbDz88MPo1KkT/vvf/+Lw4cPYunVrrfjuVXl5OYYNGwZBELBq1SocPHgQhw4dgiAIFr3O7er6eUr11MG2RIx1lUhUV1fX2fbOfw+JiYn44IMP8PLLLyMpKQlpaWmYMmVKo2ILCwvDoEGDsGLFCuTm5mLr1q149tlnGzcIIgvjvZ/3fktq7L2/KTw8PHD48GFs2rQJwcHBWLp0Kbp06YIjR44AAIYPH47s7GzMmTMHlZWVGD9+PB588EHo9XqLxmELmAjfg3379kGtVuO9995D//79ERwc3Og9Iy0lNDQUAPDrr78aX9PpdMa/9HdjqTGEhobi4MGDJv+IUlJSzDr36aefxvfff4+MjAx8//33JnVMhw4dQkVFBT7++GM88MAD6NatW6MXFYSGhiIvL8+4AAMA8vLykJGRYTw+deoUbty4gfnz52PIkCEICQlBYWGhyc2p5ubV0I0iLCwMe/fuNXnt559/hiAICAsLa1TstzMnxj59+uDkyZN3/Rn26dMHqampJos3bte2bVvo9XqT7/Gd9XR3s3fvXowYMQKTJk1C79690aVLF5Pvedu2bdGxY0f8+OOP9fbz3HPPYc2aNVi+fDk6dOiAoUOHmnV9opbCe7/p9XnvN2iue/+dunTpAmdn5zqvFR4ebjyWy+WIjo7GO++8gyNHjqB9+/YmC+pUKhX++te/YtmyZdi+fTt+/vlnk5lrR8FE+B5069YNN27cwMqVK3Hu3DmsWbMGn376qVVi6dq1K0aNGoWpU6ca/zI/99xzKC4urnemwFJjeOGFF3Djxg08++yzOHXqFHbt2oU5c+aYde6IESPg4+ODxx9/HD4+PhgxYoTJuARBQGJiIs6fP4/NmzfjnXfeaVRssbGx6NmzJ8aPH4+DBw8iLS0NTz75pMl2X0FBQXB2dsYnn3yCs2fPYteuXZg+fbrJ967m4/4ff/wR165du+sCl9deew1Hjx7FzJkzcfr0aezcuRPTpk3Dk08+afzIrSnMifGvf/0rgoKCMHr0aCQnJ+P8+fPYtWsX1q1bB8DwcZgoihgzZgxSUlJw/vx5bNu2zbhyvV+/fvD09MTrr7+OzMxM7Ny50+zvd7du3bBnzx7s3r0bZ86cwdy5c3HgwAGTNm+99RaWLVuGd999F6dOnUJ6ejr+/e9/m3xkV7MH6LvvvstFctQq8d7/B977/9Bc9/47ubm54eWXX8a8efOwfv16nDlzBu+//z62bNmC2bNnAwC2bNmCjz76CEeOHEF2djY2b96MS5cuGf/jNGfOHGzcuBEZGRnIzMzE119/DQ8PD4vGaSuYCN+DkSNHYs6cOZg9ezbuv/9+/Pe//8WHH35otXhWrVqF8PBwPPTQQxgyZIhxNs3FxeWu51hqDB06dMB3332HgwcPolevXpg+fTr++c9/mnWuQqHAE088gbS0NDzxxBMmtWY9evTAJ598gmXLliE0NBSLFi3Cxx9/3KjYBEHA5s2b4e3tjejoaIwcORIPP/wwIiIijG3UajW++uorJCUlISwsDLNmzcKiRYtMSgVkMhmWLFmC//f//h86duyI3r1713m9Hj16YOvWrdi7dy969uyJCRMm4JFHHjF+7NhU5sTo5uZmnBV4/PHHERISgqlTp6KiogIA0L59e+zbtw+enp54+OGHERYWhjlz5hhnP1QqFf7zn/9g//796NGjB959910sXLjQrPjmzZuHwYMHY8yYMRg4cCAKCwtrrUCfMmUKVq9ejW+//Ra9evVCdHQ0duzYYfIzd3FxwYQJEyCKIiZNmnRP3zOi5sB7/x947/9Dc9376zJ//nz87W9/w4wZMxAeHo6vvvoKX331FWJjYwEYSk++++47jBgxAsHBwfj73/+OuXPnYvLkyQAM99k333wTffr0QWRkJI4fP44dO3bA29vb4rG2doJk6cIUajX0ej26d++O0aNHIzEx0drhEJlt3LhxqK6uxqZNm6wdCpHN4b2fyHx8spwd2bt3L3Jzc9G7d2+UlJTgo48+woULF/DMM89YOzQisxQWFuLgwYPYtGmTyT6pRHR3vPcTNR0TYTui1+vx3nvvISsrC0qlEuHh4di9ezfuv/9+a4dGZJbevXsjPz8ff//732ttDUREdeO9n6jpWBpBRERERA6Ji+WIiIiIyCExESYiIiIih8REmIiIiIgcklUXy129etWsdmq12mTDfXvD8dk2js+2NWV8/v7+zRRN68Z7tgHHZ9s4PtvW1PHd7b7NGWEiIiIickjcPo2IyM6kpaVh1apVEEURsbGxiI+PN3l/9erVSE9PBwBotVoUFRVh9erVVoiUiMi6mAgTEdkRURSxcuVKzJ07F76+vnjjjTcQGRmJjh07Gtvc/qCFHTt24Pz581aIlIjI+pgIExHZkaysLPj5+aFdu3YAgKioKBw6dMgkEb5dSkoKxo0b15IhEtkcSZJQWVkJURQhCIK1w6nX9evXUVVVZe0wmk1945MkCTKZDC4uLmb/nJgIExHZkYKCAvj6+hqPfX19kZmZWWfbGzduIDc3F+Hh4S0VHpFNqqyshFKphELR+tMmhUIBuVxu7TCaTUPj0+l0qKyshKurq3n9WSowIiKyLSkpKRgwYABksrrXTScnJyM5ORkAsGDBAqjVarP6VSgUZre1RRyfbWvK+K5fvw5nZ+dmisjybCFhvxf1jU+hUEAQBPPvV5YKioiIrE+lUiE/P994nJ+fD5VKVWfb1NRUTJ48+a59xcXFIS4uznhs7pZF3L7JtnF8tVVVVdnMLKtCoYBOp7N2GM3GnPFVVVXV+hk3efu0Tz/9FFOmTMGrr75a5/uSJOGLL77AtGnTMGvWLJw7d66hLomIqJloNBrk5OQgNzcXOp0OqampiIyMrNXuypUrKCsrQ3BwsBWiJCJzFRQUYOjQoRg6dCh69eqFPn36GI+1Wm295x47dgzz5s1r8BqjR4+2SKypqal46qmnLNJXS2lwRnjIkCEYMWIElixZUuf7v/32G65du4Z//etfyMzMxOeff47333/f4oESEVHD5HI5Jk2ahPnz50MURcTExCAgIADr1q2DRqMxJsUpKSmIiopq9Qt/iBydSqVCUlISACAxMRHu7u54/vnnje/rdLq7lgr07NkTPXv2bPAaW7dutUywNqjBRDg0NBS5ubl3ff/w4cOIjo6GIAgIDg5GWVkZCgsL4ePjY9FAbYVeD+zZ44xr18z/CMXDQ4bSUrdmjMq6OD7bZu/je+QRoE0ba0dhWREREYiIiDB5LSEhweS4JXaKOHJEifPnFXjssYpmvxaRI5kxYwacnZ2Rnp6OyMhIjBkzBm+++Saqqqrg6uqKxMREdOnSBampqVi6dCnWrFmDxMREXLlyBdnZ2bhy5QqmTJliLI3q2rUrMjMzkZqain/+85/w8fFBRkYGevTogU8++QSCIGDXrl14++234ebmhr59++LixYtYs2bNXWMsLCzEq6++iuzsbLi4uGDhwoUIDQ3Fr7/+ijfffBMAIAgCNm7ciLKyMrzwwgsoKSmBXq/HBx98gP79+7fI9/Kea4QLCgpMCpJ9fX1RUFBQZyJsawsviooAc8uIJAn48UcZPvlEjnPnmjLDYme/iWvh+Gyb/Y7Pz09EQoL9LgyypvXr3bB5syv+8pcK3GU9HhE1UU5ODrZs2QK5XI6SkhJs2rQJCoUCKSkp+L//+z+sWLGi1jlZWVlYv349ysrK8Oc//xlPPfUUlEqlSZvff/8dP/30E/z8/DBmzBgcOnQIPXr0wD/+8Q9s3LgRgYGBePHFFxuMLzExEeHh4fjiiy+wb98+TJ8+HUlJSVi6dCnef/999O3bF2VlZXB2dsZXX32FwYMHY/r06dDr9aioaLn/PLfoYjlbWXiRlaXA8uXu+PZbN1RVNS6p7d1bi2XLStGnT/11O7dTqVQoKChobJg2g+OzbfY+Po1G1ej7y90WXZCpyEgt1q51x5kzCnTvbr+Ld8ixvPmmF06eVDbcsBFCQ6vxzjvFjTpn5MiRxgV8xcXFmDFjBs6fPw9BEFBdXV3nObGxsXB2doazszPUajVu3LhR637Wq1cv42thYWG4dOkS3NzcEBQUhMDAQABAfHw8vvrqq3rjO3jwoDEZHzRoEAoLC1FSUoK+ffvi7bffxqOPPoqHHnoI/v7+6NWrF1599VXodDoMHz68Rbd0vOdEWKUy/SVS3wrl1mrLFhcsXOgFnc4ws3vligIuLhIee6wcfftqYW4JXefOOkREVJvdvoZaDTg7i40P3EZwfLbN3sfn5gaUl1s7CvsUGWmYEDh82ImJMJGFubn9UbL24YcfIioqCitXrsTVq1fx6KOP1nnO7VvAyeVy6PX6Wm2cnJxM2lh6B4qXXnoJsbGx+OmnnxAfH49vvvkGAwYMwIYNG7Br1y7MnDkTzz77LMaOHWvR697NPSfCkZGR2LlzJx544AFkZmbCzc3NpuqDMzIUeOWVNujcWY/wcMP/oDp1Ksf48eVQq+33lz8RUXMLCtJDrdbj8GEnjB/P/22QfWjszG1LKCkpgZ+fHwBg3bp1Fu9fo9Hg4sWLuHTpEgICAsxaXNe/f39s3LgRM2fORGpqKlQqFTw9PXHhwgWEhIQgJCQEaWlpyMrKgouLC9q3b48nn3wSWq0WJ06caD2J8Mcff4yTJ0+ipKQEzz//PMaNG2f838GwYcPQu3dvHD16FC+//DKcnJzMqhtpLSoqBDz/vA88PCR8800+2rZl4ktEZCmCYJgVPnzYqeHGRNRkL7zwAmbMmIHFixdj6NChFu/f1dUV77//Pp588km4ubmZtRPFK6+8gldffRVxcXFwcXHBxx9/DAD4/PPPkZqaCplMhuDgYMTExGDLli1YunQpFAoF3N3dsXjxYouP4W4ESZKkFrvaHa5evWpWu+aqEZ41yxv//a8bvvmmANHR1nsuNzcvt20cn21ryvgctUa4KffspUtc8O77Khw/fg2+vvYx2cB/E7atKeMrLy83KUVozZrrgRplZWVwd3eHJEmYPXs2OnfujGeffdbi12mIOeOr6+fV5Adq2KsjR5T4z3/cMXVqqVWTYCIie+X13nt4Zd2DAAz3XCKyXV9//TWGDh2KmJgYlJSUYMKECdYOySIc9hHLv/1m+KhuypQyK0dCRGSf9Go12pw9Bo3iAg4f9sWwYZx0ILJVzz77rFVmgJubw84IZ2QooFLpuSCOiKiZVN7aLnOy31bWCRNRq+TAibAS3brpGr3VGRERmUev0UDXqRNGCttx7JgTtOZvr05E1CIcMhGWJODMGQW6deO+lkREzUYQUBkXh5CcnyGrLEd6OuuEiah1cchE+OpVGUpKZOjWre4nrxARkWVUxsVBoatCLHaxPIKIWh2HTIQzMgyzEpwRJiJqXtr+/SF6eOBx9y1MhIma6LHHHsOePXtMXluxYgVef/31es85duwYAGDChAkoKiqq1SYxMRFLly6t99o7d+7EmTNnjMcffvgh9u7d24jo65aamoqnnnrqnvu5Vw6aCBs2ywgO5owwEVGzcnJC1eDBGK77Hr8fl1s7GiKbFB8fjy1btpi8tmXLFsTHx5t1/tq1a+Ht7d2ka9+ZCL/22muIjo5uUl+tkYMmwkr4+enh42O1Z4kQETmMyrg4+FZdgyr7BG7e5AplosZ65JFHsGvXLmhvrTi9dOkSrl+/jv79++P111/HQw89hJiYGCxatKjO8/v374+CggIAwOLFizFo0CDEx8fj7NmzxjZff/01Hn74YcTFxeFvf/sbKioqcOjQISQlJeG9997D0KFDceHCBcyYMQPbtm0DAPzyyy8YNmwYYmNj8corr6Cqqsp4vUWLFmH48OGIjY1FVlZWveMrLCzEpEmTEBcXh5EjR+LkyZMAgF9//RVDhw7F0KFDMWzYMJSWluL69ev4y1/+gqFDh+LBBx/EgQMH7ul766CJsIKzwURELaTqwQchCQJGYhsXzBE1gY+PD3r16oXdu3cDMMwGjxo1CoIg4B//+Ad27NiB5ORk7N+/H+np6Xft5/jx49i6dSuSkpKwdu1aY+kEADz00EP4/vvvkZycjC5duuA///kP+vbti6FDh2Lu3LlISkpCp06djO0rKysxc+ZMfPbZZ9i1axd0Oh3WrFljfF+lUuGHH37AhAkTGiy/SExMRHh4OJKTk/H6669j+vTpAIClS5fi/fffR1JSEjZt2gQXFxds3LgRgwcPRlJSEpKSkhAWFtaUb6mRwz1QQxQNO0ZMmFBu7VCIiByCqFajIqwXhv3+I344MQMPPMB91Mh2eb35JpS3ZiwtpTo0FMXvvFNvm5ryiOHDh2PLli1ITEwEAHz33Xf4+uuvodfrcf36dZw5cwbdunWrs48DBw5gxIgRcHV1BQAMHTrU+F5GRgYWLlyI4uJilJWVYfDgwfXGc/bsWQQGBkKj0QAAxo4diy+//BJ/+9vfABgSawDo0aMHduzYUW9fBw8exIoVKwAAgwYNQmFhIUpKStC3b1+8/fbbePTRR/HQQw/B398fvXr1wowZM6DT6TB8+HCEh4fX23dDHG5GODtbjspKGbp354wwEVFLER/oh0gcRsYxvbVDIbJJw4cPx759+3DixAlUVFSgR48eyM7OxrJly7Bu3TokJycjNjbWWJ7QWDNnzsR7772HXbt2YebMmU3up4azszMAQC6XQ69v2r/7l156CR9++CEqKysRHx+PrKwsDBw4EBs2bICfnx9mzpyJ9evX31OcDjcjXLNjRHAwd4wgImop2n794LFsGXDkBICu1g6HqMkamrltLu7u7oiKisIrr7xiXCRXUlICV1dXeHl54caNG9i9ezcGDRp01z4GDBiAmTNn4qWXXoJer0dSUhImTJgAACgtLUW7du1QXV2NTZs2wc/PDwDg4eGBsrKyWn1pNBpcunQJ58+fR+fOnbFhwwYMGDCgSWPr378/Nm7ciJkzZyI1NRUqlQqenp64cOECQkJCEBISgrS0NGRlZcHd3R1t27bFk08+Ca1WixMnTmDs2LFNui7gkIlwzY4RTISJiFqKtm9fAEDnK7+irCwY7u5crEzUWPHx8Zg8eTI+++wzAEBYWBjCw8MRHR0Nf39/9L317+xu7r//fowaNQpDhw6FWq1Gr169jO+99tprGDlyJHx9fdG7d2+UlpYCAMaMGYPXXnsNK1euxPLly43tXVxc8M9//hPPPfcc9Ho9evbsaUyqG+uVV17Bq6++iri4OLi4uODjjz8GAHz++edITU2FTCZDcHAwYmJisG3bNixZsgQKhQLu7u5YvHhxk65ZQ5AkyWp3o6tXr5rVTq1WIy8vzyLXnDq1DY4cccL+/bkW6c8SLDm+1ojjs20cX23+/v7NFE3rdq/3bPc+g7H3WneIm1ehb1/brRPmvwnb1pTxlZeXw83NrZkisiyFQgGdzn4n+8wZX10/r7vdtx2uRjgjQ8nZYCIiK6ju3w9RSMXxNO4nTEStg0MlwjodcPasggvliIisQB4dCV8UoODXc9YOhYgIgIMlwufPK6DVCpwRJiKyAm0/Q/2i17GDVo6EiMjAoRLh06cNC+U4I0xE1PL0nTujxPU+aK7vR0WFtaMhMp8Vl6lhPuoAACAASURBVFNREzTm5+VQifCZM0rIZBI0Gs4IExG1OEFAXkh/PCDtw+nTfMIc2Q6ZTGbXC9DsiU6ng0xmfnrrUNunnT6tQKdOetx6oAoREbUw2aBIdD66Ddv35aN3by9rh0NkFhcXF1RWVqKqqgqCIFg7nHo5Ozvf88MwWrP6xidJEmQyGVxcXMzuz6ES4YwMBbp1Y1kEEdm3tLQ0rFq1CqIoIjY21rj5/u1SU1Oxfv16CIKAoKAgTJ8+vUVicx0aCfwLkB84DEx7sEWuSXSvBEEwPpa4teP2d43jMIlwZSVw4YICo0ZVWjsUIqJmI4oiVq5ciblz58LX1xdvvPEGIiMj0bFjR2ObnJwcbN68Ge+++y48PDxQVFTUYvHp7g9HpeAC9ZnDAJgIE5F1OUwifPasAnq9cO8zwlotnH/9FVV//jNwWw2K/MIFOO/Z06QuZe7ucKvj8YX2guOzbfY+PowaBfj6WjsKi8nKyoKfnx/atWsHAIiKisKhQ4dMEuFdu3Zh+PDh8PDwAAB4e3u3XIBKJbLbhCPgRlrLXZOI6C4cJhHOyDAszOjW7d6K3T0//hieixfj5oIFKL/1KEGhogLqxx6DPCenyf22uaeoWj+Oz7bZ8/h0HToAQ4daOwyLKSgogO9tib2vry8yMzNN2tQ8IW7evHkQRRFjx441edRqc8sL7ImwY+txo1SCm0frrrckIvvmQImwAkqlhM6dm54Iy65ehfuyZZAEAZ6LFqEiPh6Spyfcly+HPCcH+WvXorpnz0b3q1KpUFBQ0OS4WjuOz7bZ/fiCgoDSUmuH0aJEUUROTg7eeustFBQU4K233sKiRYvg7u5u0i45ORnJyckAgAULFkCtVpvVv0KhqLftpb594X1sJS6mlyDwkT81fSBW0tD4bB3HZ9s4vkb2Z7GeWrmMDCU0Gh2cnJreh9f//R8ESULh0qVQPfccPJYsQdmkSfBYsgQVI0ag6sEm1rup1RBb+SrUe8Lx2TZ7H5+Li10lwiqVCvn5+cbj/Px8qFSqWm26du0KhUKBtm3bon379sjJyUGXLl1M2sXFxSEuLs54bO4ClYYWs0i9NQCAa9tToe5veztHcDGSbeP4bFtTx+fv71/n6w6zj3BGhuKeniinPHECbt9+i9LJk1E5ciTK//IXeKxYAe/XX4dQVYXi2bMtGC0RUdNoNBrk5OQgNzcXOp0OqampiIyMNGnTr18/pKenAwCKi4uRk5NjrCluCfcN6QItlFCcONFi1yQiqotDzAiXlQnIzlYgIaG8wbaKrCw4/fJLrdfdNmyAXqVC6bRpAICS11+H6/ffw/WHH1A6eTL0Go3F4yYiaiy5XI5JkyZh/vz5EEURMTExCAgIwLp166DRaBAZGYmePXvi2LFjmDlzJmQyGcaPHw9PT88Wi9G1jRNOK8OhunC8xa5JRFQXh0iEMzNrHq3c8Iyw17x5cNm7t9brkkyGm4sWQfIyfIyn79ABJTNnwm3tWpTMmGHZgImI7kFERAQiIiJMXktISDB+LQgCnn76aTz99NMtHZpRtm8vDLqxBeWSBNhz6Q0RtWoOkQhnZBiGGRzcwNZpkgTl77+j/H/+B8X/+7+mbykUxiS4RulLL6H0hRcAudyS4RIR2b3Czj3Q5toqVF6+AjGgY8MnEBE1A4eoET59WgkXFwlBQfp628muXYO8oADa3r0hqlQmf+5Mgo2YBBMRNZqu5/0AgLJffrdyJETkyBwiET5zRoGuXasbzFmVtxaP6MLCWiAqIiLH5TEwGDrIUZXKRJiIrMchEuFz5xTo0qXh+uCaRLg6JKS5QyIicmidQ5U4iVA4p3PnCCKyHodIhG/elEGlEhtspzx5ErqgIEgtuHqaiMgRtW8v4ri8N+7LPgZIkrXDISIHZfeJsF4PFBfL4O3d8I1WmZ6OapZFEBE1O0EALrXtBa/KG5Bdu2btcIjIQdl9IlxcbNiWx9u7/hlhobQU8gsXUB0a2hJhERE5vGKNYcGc8nfWCRORddh9IlxUZBhiQ4mw4tQpCJLEGWEiohYi69kdACD8ftrKkRCRo7L7RLi42LxEmDtGEBG1rA6h7riIQGiPZFg7FCJyUHafCN+8WVMaUX+NsPLkSYht2kDv798SYREROTyNRocTuB9OZzgjTETWYfeJsLmlEcqTJw31wXzUJxFRiwgK0uF3hMM7JxPQaq0dDhE5ILtPhGtKI7y86kmEdTooT53iQjkiohbk5SXhnFsY5KIOinPnrB0OETkgu0+Ea2aE27S5e2mE4vx5CJWVXChHRNTCCjsaJiCUp1keQUQtT2HtAJpbUZEApVKCq+sdibBWC9dNmyArLoYiw7BQg4kwEVHLEoO7oPqMAopTp4D4eGuHQ0QOxu4T4Zs3ZfDyEmuV/nosWQKvRYuMx/r77oOua9cWjo6IyLH5d5LhDILR+TR3jiCilmdWIpyWloZVq1ZBFEXExsYi/o7/td+4cQOfffYZiouL4eHhgWnTpsHX17dZAm6sup4qJ7t+HR6ffoqKhx/GzVvJsOTqCjg5WSNEIiKH1amTHidwPzTpqdYOhYgcUIM1wqIoYuXKlZg9ezY++ugjpKSk4PLlyyZt1q5di+joaCxatAiPPfYYvvnmm2YLuLGKioRaO0Z4fvghhOpqFM+ZA8nbG5K3N5NgIiIrCAw0bKHmknMJQmmptcMhIgfTYCKclZUFPz8/tGvXDgqFAlFRUTh06JBJm8uXLyM8PBwAEBYWhsOHDzdPtE1QVCQzSYQV6elw++9/UTZxIvSdOlkvMCIiQqdOevwOw+8PBRfMEVELa7A0oqCgwKTMwdfXF5mZmSZtgoKCcPDgQTz88MM4ePAgKioqUFJSAk9PT5N2ycnJSE5OBgAsWLAAarXavCAVCrPb3qm0VIngYNF4vmLBAsDHB07vvAO1j0+T+rS0exmfLeD4bBvHR83Jz0+P04pwQAcoMzJQHRlp7ZCIyIFYZLHchAkT8MUXX2DPnj0ICQmBSqWCTFZ7sjkuLg5xcXHG47y8PLP6V6vVZre9U0FBO7i4VCIvrwiyvDz4/fQTimfNQqleDzSxT0u7l/HZAo7PtnF8tfnzCZQWI5cD+oAAVGS7c0aYiFpcg4mwSqVCfn6+8Tg/Px8qlapWm1mzZgEAKisrceDAAbi7u1s41MaTJNPSCNmtX3Y6jcaaYRER0W0CO4nIvBaGbqdOWTsUInIwDdYIazQa5OTkIDc3FzqdDqmpqYi846Or4uJiiKIh2dy0aRNiYmKaJ9pGKi8XoNf/sVhOdiuhF+9I5ImIyHqCgvRI04UbZoSluz/8iIjI0hqcEZbL5Zg0aRLmz58PURQRExODgIAArFu3DhqNBpGRkTh58iS++eYbCIKAkJAQTJ48uSVib9DNm4bNg2u2T5MVFAAAxFaytRsRERl2jjhS3QNPFX4BWW4uxHbtrB0SETkIs2qEIyIiEBERYfJaQkKC8esBAwZgwIABlo3MAmoer8wZYSKi1qtTJz3W4n4AgCIjA1omwkTUQhosjbBlNYmwl9etRLiwEAATYSKi1iQwUGfcQk2ZwSfMEVHLsetEuLjYMLw2bW6VRuTnQ/TyApRKa4ZFRES3CQzU4wbaotRNzZ0jiKhF2XUi/EeN8K0Z4YICzgYTEbUy7u4S7rtPj4seoZwRJqIWZZF9hFurO0sj5Pn5TISJyO6lpaVh1apVEEURsbGxiI+PN3l/z549WLt2rXErzBEjRiA2NtYaoRoFBuqRfuV+hGSsAkQRqGMveiIiS7PrRLi4WAZBkODl9ceuEfoOHawcFRFR8xFFEStXrsTcuXPh6+uLN954A5GRkejYsaNJu6ioqFazww8ABAXpcPhsOMaVl0N++TL0gYHWDomIHIBd/5e7qEiAl5dknFhgaQQR2busrCz4+fmhXbt2UCgUiIqKwqFDh6wdVoOCgvTYd7MHALBOmIhajF0nwjdv/vFUOUiSYUaYewgTkR0rKCiA7233OV9fXxTc2kP9dgcOHMCsWbOQmJjYKh6hbbJzBBNhImohdl0aUVQkM9YHC2VlELRazggTkcPr06cPHnjgASiVSiQlJWHJkiV46623arVLTk5GcnIyAGDBggVQq9Vm9a9QKMxuW+P++wWUQInytkFwv3ABLo08vyU1ZXy2hOOzbRxfI/uzWE+tUHGx8MdT5fgwDSJyACqVCvm37ncAkJ+fb1wUV8PT09P4dWxsLL766qs6+4qLi0NcXJzx2NyZY7Va3ehZZm9vGQA/XPXphqDjx1vFLPXdNGV8toTjs20cX938/f3rfN2uSyOKimQmW6cBTISJyL5pNBrk5OQgNzcXOp0OqampiIyMNGlTeOvhQgBw+PDhWgvprMHPT4STk4RzbmFQZGUB1dXWDomIHIBdzwibJMKcESYiByCXyzFp0iTMnz8foigiJiYGAQEBWLduHTQaDSIjI7Fjxw4cPnwYcrkcHh4eePHFF60dNmQyoEMHPU5I4RhWXQ3F+fPQBQdbOywisnN2ngjfVhpRMyPMxXJEZOciIiIQERFh8lpCQoLx6yeeeAJPPPFES4fVoKAgHfZfubVzxKlTTISJqNnZbWlEVRVQWcnSCCIiWxEQoMcvuaGQ5HI+YY6IWoTdJsJ3PlVOVlAASamEdNsiESIiaj0CA/W4XuQGbVBnKJgIE1ELsPtEuE2bP3aNEFUqQBCsGRYREd1FYKAOAHCzQwj3EiaiFmHHibAh4b29NIJlEURErVdgoB4AcNk3HIoLFyCUllo5IiKyd3acCJuWRsiZCBMRtWoBAYYZ4dMuPQEAylOnrBkOETkAu0+Eb98+jTtGEBG1Xm3aSPD0FHFU7AUAUKSnWzkiIrJ3dpsIFxcbSiOMNcKFhZwRJiJqxQTBUB5xLC8Qeh8fKJkIE1Ezs9tE+ObN20ojqqshu3mTiTARUSsXGKhD9iUFdGFhTISJqNnZbSJcVCSDq6sIJydAdvMmAEDP0ggiolYtIECPS5fk0IaFGXaO0OmsHRIR2TG7TYSLi297qlzN45V9fKwZEhERNSAoSIfKShkKAsIhVFVBcfastUMiIjtmt4nwzZsytGlzx1PlOCNMRNSqBQQYtlA752V41DLLI4ioOdltIpyfL4NK9ceOEQAfr0xE1NrV7CV8SuwOydmZiTARNSs7ToTl8PXljDARkS3p2NFQE3zhiguqu3VjIkxEzcpuE+GCAlntRJg1wkRErZqrK9CunWHBXHVYmGEvYUmydlhEZKfsMhGurjbUCPv6Gj5ikxUUQPTyApycrBwZERE1JCBAj+xsBarDwiAvKIDs2jVrh0REdsouE+HCQsOwbq8RZn0wEZFtCAzUITtbDl1YGAAumCOi5mOXiXB+vmFYNaUR8oICJsJERDYiKEiPq1flKNOEAGAiTETNxyESYRkTYSIimxEYqIMoCrhU1Aa6Tp2g/P13a4dERHbK/hPh6mrIL16E3t/fylEREZE5OnUyrO/IzlagOjwcyhMnrBwREdkru0yECwr+SISdjh6FrLQUVX/+s5WjIiIicwQG3tpC7YIc1T17QnHpEoRbu/8QEVmSXSbC+flyCIIEHx8Rzrt3Q5LLUTVokLXDIiIiM7RrJ8LFRUJ2tgLa++8HADhxVpiImoGdJsKGxyvL5YDznj3Q9ukDycvL2mEREZEZBMEwK3zxohzVtxJh5fHjVo6KiOyR3SbCvr4iZHl5cDpxAlVDhlg7JCIiaoSgID0uXlRAanNrwRwTYSJqBnaZCNc8Vc75558BgIkwEZGNCQoyzAhLElDdowcTYSJqFnaZCNfMCDvv2QO9SmX8aI2IiGxDUJAe5eUy5OXJoO3ZE4rLlyHjgjkisjD7TYR9dHD++WfDbLDMLodJRGS3goIMO0ewTpiImpPdZYh6veERyz3ENMjz81E1eLC1QyIiokYKCjLsJXzxouKPRPjYMWuGRER2yO4S4Zs3ZRBFARG5SQDARJiIyAZ17KiDIEjIzpZD8vKCrnNnzggTkcXZXSJc81S5P10/iOpu3SDed5+VIyIiallpaWmYPn06pk2bhs2bN9+13f79+zFu3DicPXu2BaMzj4sL4Ocn4sIFBQBA27MnE2Eisji7TYR9Cs5Bp9FYORoiopYliiJWrlyJ2bNn46OPPkJKSgouX75cq11FRQV27NiBrl27WiFK83TqpEN2thyAYecIxdWrkOXlWTkqIrIndpkIy6CH542L0HXqZO1wiIhaVFZWFvz8/NCuXTsoFApERUXh0KFDtdqtW7cOY8aMgVKptEKU5gkMNOwlDBgSYYAL5ojIshTWDsDS8vNl6IjLkFVroWciTEQOpqCgAL6+vsZjX19fZGZmmrQ5d+4c8vLyEBERga1bt961r+TkZCQnJwMAFixYALVabVYMCoXC7Lb1CQ2VYd06Odzc1HAbMgSSIKBNRgb048bdc9/3wlLja604PtvG8TWyP3MapaWlYdWqVRBFEbGxsYiPjzd5Py8vD0uWLEFZWRlEUcQTTzyBiIgIiwXZGAUFMnRBFgBwRpiI6A6iKGLNmjV48cUXG2wbFxeHuLg443GemWUJarXa7Lb19+MKwAe//XYT3brpcF9oKMTdu5H/wgv33Pe9xWWZ8bVWHJ9t4/jq5u/vX+frDZZGmFNvtmHDBgwcOBALFy7EjBkzsHLlykYHaCn5+TKEuxhmP5gIE5GjUalUyM/PNx7n5+dDpVIZjysrK3Hp0iW8/fbbmDp1KjIzM7Fw4cJWuWDu9r2EAaBqwAAojxwBtFprhkVEdqTBRNicejNBEFBeXg4AKC8vh4+PT/NEa4b8fDlCnbIgOTtDbN/eanEQEVmDRqNBTk4OcnNzodPpkJqaisjISOP7bm5uWLlyJZYsWYIlS5aga9eu+Pvf/w5NK1xcfPtewgCg7d8fsspKKE+csGZYRGRHGiyNMKfebOzYsXjvvfewc+dOVFVVYd68eZaP1Ez5+TJ0lWVBFxjIJ8oRkcORy+WYNGkS5s+fD1EUERMTg4CAAKxbtw4ajcYkKW7tfHxEeHqKxhlhbb9+AADnAwdQ3aePNUMjIjthkcVyKSkpGDJkCEaNGoUzZ87gk08+QWJiImR3JKItsfCiqEiBzvpzkAcH20yxOAvbbRvHZ9vscXwRERG11mkkJCTU2fZ///d/WyCiphEEQ3lEzV7C4n33oVqjgdOBA4AZNc5ERA1pMBFuqN4MAH766SfMnj0bABAcHIzq6mqUlJTA29vbpF1LLLzIvd4W/uVZKPcfgGIbKRZnYbtt4/hsW1PGd7dFF2R5Go0Ov/3mZDzW9u8P1+3bAVHkp35EdM8avIs0VG8GGH6R/P777wCAy5cvo7q6Gl5eXs0TcT0kCXAuuA5nfQUXyhER2YEuXXS4dEmOigrDsbZ/f8iKiqA4fdq6gRGRXWhwRticerOnnnoKy5Ytw/bt2wEAL774IgRBaPbg71RUJCBIb1j5zD2EiYhsn0ajgyQJuHBBgZAQHbQDBgAAnA4cgC401MrREZGtM6tGuKF6s44dO+Ldd9+1bGRNkJ/PPYSJiOyJRmPYQu3sWUMirO/YETp/fzjv34/yiROtHB0R2Tq7KrAqKJCjC7IgyhXQd+xo7XCIiOge/elPhi3Uzp79Y95GO2AAnA4eNNTDERHdA7tKhGtmhCvaBQAKu3t6NBGRw3Fzk9C+vR5ZWbclwv36QZ6bC/m5c1aMjIjsgV0mwrrATtYOhYiILKRLFx3OnfsjEa4aOBAA4JySYq2QiMhO2FUiXFggGGqEuwRZOxQiIrIQjUaHs2cVxkoIvUYDXYcOcP7lF+sGRkQ2z64SYX1uIbxRDKlLJ2uHQkREFqLR6FBSIsONG7d+ZQkCqqKj4bxvH6DTWTc4IrJpdpUIu1w5D4BbpxER2ZOanSNurxOuio6GrLgYymPHrBUWEdkBu0qEvXNvJcKdO1s5EiIispQuXf7YQq1G1aBBkAQBznv3WissIrIDdpUID7z4LUpkXtAFBFg7FCIispD27fVwcRFNEmFJpUJ1jx5w/vlnK0ZGRLbObhJhp717MbBgB77u9A/A2dna4RARkYXIZIb9hG9PhAFDeYTT0aMQSkqsFBkR2Tr7SIT1eni/8w4uKTphV+jz1o6GiIgsrGbniNtVRUdD0OvhnJpqpaiIyNbZRSLsun49lKdO4W2X9+Hqw9lgIiJ706WLDpcuyVFV9cdr2j59ILq5sTyCiJrM5hNhobwcXgsXQhsRgTWVCfD2Fq0dEhERWZhGo4MoCrhw4bZZYWdnaAcO5II5Imoym0+ElYcPQ379OvJfmIFqnQxeXnz2PBGRvalrCzUAqBoyBIrz5yHPyrJGWERk42w+EZbdWiRx07MDAMDLizPCRET2piYRzsw0TYQrRowAALhu397iMRGR7bP5RFgoLQUA3BS9AIClEUREdsjdXUJAgA4ZGUqT10V/f2gjI+G6bZuVIiMiW2bzibCsuBgAUCi2AQB4e7M0gojIHnXvrsPp04par1eMHAnlyZOQnztnhaiIyJbZfCJcMyOcr/UEwNIIIiJ71b17Nc6dU5jsHAEAFY88AgCcFSaiRrP5RFhWUgLR1RVFZU4AmAgTEdmr7t110OmEWvsJi/7+0Pbpw0SYiBrN5hNhoaQEkpcXiooEAECbNiyNICKyR927VwMATp9W1nqvYuRIKNPTIT9/vqXDIiIbZvOJsKykBKKHB4qKDEPx9OSMMBGRPdJodFAqpbrrhFkeQURNYPOJsFBaCsnTE8XFMri6inBysnZERETUHJRKwxPmTp2qPSMsdugAbUQEXLdutUJkRGSrbD4RlhUX30qEBe4YQURk57p3r65zRhgAyv/yFyhPnoTi5MkWjoqIbJXNJ8JCaSlET08UFcm4UI6IyM51767D1asK47qQ21WMGQNJqYTb+vVWiIyIbFHd/622IUJJCSQPDxRdkfFhGkREANLS0rBq1SqIoojY2FjEx8ebvP/jjz/ihx9+gEwmg4uLC5577jl07NjRStE2Ts2CuTNnlOjbV2vynqRSoTIuDq4bN6J49mxDLQURUT1sfkZYVlIC8VZphJcXSyOIyLGJooiVK1di9uzZ+Oijj5CSkoLLly+btBk0aBASExPx4YcfYsyYMfjyyy+tFG3jhYQYHrV86lTd8zgVY8dCnpcH5z17WjAqIrJVtp0Ii6LJYjnOCBORo8vKyoKfnx/atWsHhUKBqKgoHDp0yKSNm5ub8evKykoIQu0yg9bK318PT0+xzi3UAKDywQeh9/VleQQRmcWmSyOE8nIIknRbjTBnhInIsRUUFMDX19d47Ovri8zMzFrtdu7cie3bt0On0+HNN9+ss6/k5GQkJycDABYsWAC1Wm1WDAqFwuy2TREeDpw96wq1+i6lD3/9K1yWL4daJgNUKotfv7nHZ20cn23j+BrZn8V6sgKhuBgAIHrU7BrBGWEiInOMGDECI0aMwL59+7Bhwwa89NJLtdrExcUhLi7OeJyXl2dW32q12uy2TaHReOO771xx40Ye6prMVowahbb//jfKv/gC5c88Y/HrN/f4rI3js20cX938/f3rfN2mSyNkpaUAgAqlJ0RR4K4RROTwVCoV8vPzjcf5+flQ1TMrWlfpRGsXElKNoiIZcnLq/hWmCwtDdVgY3NesASR+UkhEd2fTibBQUgIAKJV5AQD3ESYih6fRaJCTk4Pc3FzodDqkpqYiMjLSpE1OTo7x66NHj6J9+/YtHeY9qVkwd/LkXUojBAGlU6ZAmZHBRXNEVC+bLo2Q3UqEi+ANAJwRJiKHJ5fLMWnSJMyfPx+iKCImJgYBAQFYt24dNBoNIiMjsXPnTpw4cQJyuRweHh6YOnWqtcNulPDwashkEo4dc0JcXFWdbSri4+G1YAE8li1DVUxMC0dIRLbCphPhmhnhm2LNjDATYSKiiIgIREREmLyWkJBg/HrixIktHZJFubtLCA7WIS2tnn2CnZxQNmkSvD74AIr0dOjCwlouQCKyGTZdGlFTI1yoN8wIszSCiMgx9OxZjWPHlPWWAJeNHw/RzQ0ey5e3XGBEZFNsOhGu2TUir5qlEUREjqRnTy3y8+W4fFl+1zZSmzYof/xxuG7ZAtm1ay0YHRHZCptOhGtmhPOrPAEwESYichS9exsetVxveQSAsilTAL0eHp9+2hJhEZGNselEWCgpgejujqJSQ6kzH6hBROQYunevhpOTYcFcffRBQShPSID72rWQX7rUQtERka2w+URY8vTEzZsyeHqKkN/9EzIiIrIjTk5AWFh1gzPCAFDyyiuATAbPDz9sgciIyJbYdCIsKymB6OmJ4mIZyyKIiBxMz57VOH5cCb2+/naivz/KJk6E68aNUJw82TLBEZFNsOlEWCgtheThgeJigWURREQOplcvLcrKZDh7tuGdQEumToXk5QWvBQtaIDIishU2nQjLiouNM8LcQ5iIyLH06mVYMPfbbw2XR0g+PiidOhUuu3bB6cCB5g6NiGyETSfCQmmpsUaYiTARkWPRaHTw8BAbXDBXo2zSJOjbtoXnwoWodwNiInIYNp0I/1EjzNIIIiJHI5MBPXoYHqxhDsnVFSUvvwzn/fvh9MsvzRwdEdkCm06EhZKSWzXCXCxHROSIevXSIj1diaoq89qXP/EEdP7+8OKsMBHBlhNhvR6ysjLoPbxQUiLj45WJiBxQZGQ1qqsFpKWZVx4BZ2eUzpwJp99+g3NycvMGR0Stns0mwkJZGQCgQml4qhxrhImIHE+/flUQBAm//mpmIgygfOxY6Dp1MswK63TNGB0RtXYN7zkDIC0tDatWrYIoioiNjUV8fLzJ+6tXr0Z6ejoAQKvVoqioCKtXr7Z4sLeTlZQAAMrkXgD4eGUiIkfk4yOhe3cdDhwwPxGGUoni2bOhevZZeC5ciJLZs5svQCJq1RpMhEVRxMqVKzF37lz4+vrijTfeQGRkJDp27Ghs88wzatQKhwAAIABJREFUzxi/3rFjB86fP98swd5OuJUIl8i8AYClEUREDmrAgCqsW+eG6mpAad66OVQ+8gjKxo+H55Il0EZGomrYsOYNkohapQZLI7KysuDn54d27dpBoVAgKioKhw4dumv7lJQUDBo0yKJB1qUmES6SDKURnBEmInJMAwZoUV4uw/HjZmbBtxS9/Ta0998PnxkzIL94sZmiI6LWrMFEuKCgAL6+vsZjX19fFBQU1Nn2xo0byM3NRXh4uOUivAtZaSkAIL/aMCOsUjERJiJyRAMGaAEA+/c7N+5EFxcULlsGSBJ8nn0WqKhohuiIqDUzq0bYXCkpKRgwYABksrrz6+TkZCTfWqW7YMECqNVqs/pVKBS12tZcoUzRHgDQtWsbmNldq1PX+OwJx2fbOD5q7dRqEV26VGP/fidMndq4c/VBQShcvBi+EyeizZw5uJmYCAhC8wRKRK1Og4mwSqVCfn6+8Tg/Px8qlarOtqmpqZg8efJd+4qLi0NcXJzxOC8vz6wg1Wp1rbZuV6+iDYALBYaPwkQxD2Z21+rUNT57wvHZNo6vNn9//2aKhppqwAAttmxxhV4PyOWNO7dq2DCUTJ8Oz8WLoY2IQPn48c0TJBG1Og2WRmg0GuTk5CA3Nxc6nQ6pqamIjIys1e7KlSsoKytDcHBwswR6p5oa4aulbdCmjQiFRee2iYjIlgwcqEVJiQzp6Y2rE65R8uqrqBwyBN7z5kF59KiFoyOi1qrBRFgul2PSpEmYP38+Zs6ciYEDByIgIADr1q3D4cOHje1SUlIQFRUFoYU+UpKVlEASBOSUeMHHh/XBRESOrH9/w6PlGrOfsAm5HIX//jf0fn5QTZoE+eXLFoyOiFors+ZRIyIiEBERYfJaQkKCyfG4ceMsF5UZah6vnF+ogK8vE2EiIkfWvr2ITp0M+wk/91xZk/qQfHxQ8OWXUI8ZA9VTTyFv82ZIXl4WjpSIWhObfbKcrLQUkocHCgpkUKn01g6HiIisLCqqCr/+6nxPD4vTBQejYMUKKM6dg+pvfwO0WssFSEStjs0mwkJJCUQvr1uJMGeEiYgc3ZAhVSguluHIkSaWR9yiHTQINxcuhPO+fVBNnAihuNhCERJRa2OzibCspASicUaYiTARkaP785+roFBI+OmnRu4nXIeKceNwc9EiOO/bB3V8POTZ2RaIkIhaG5tNhIXSUuhcPaHVCqwRJiIieHlJiIzUYvduF4v0V/7XvyL/668hv3YN6pEj4ZSaapF+iaj1sN1EuLgYlc6GRQzcNYKIiAAgJqYK6elKXL9umV9v2kGDcGPrVoht2sA3IQEe//43IPJ3DpG9sNlEWFZaijK5IRFmaQQR0R/S0tIwffp0TJs2DZs3b671/rZt2zBz5kzMmjUL77zzDm7cuGGFKJtHTEwlAGDPnnsvj6ih79IFed9/j8qRI+H1wQdQPPooZNevW6x/IrIem02EhZISlP7/9u49vKkqXfz4dydpm/SSNhegXASkwMxYBMRyQH6AAkVAQTueURh1xKPiYBUEj44VxEFHBC8IinhgsOMNDoOIIHIGGRhAVNSDOngB5SIoHemxtClt0jZtkr1/f2wSqFAo0Dbd6ft5njxNdlaSd3W3K29W3r22KQWQRFgIIcJUVSU/P59p06Yxb948PvzwQ/71szVxO3fuzJw5c3jmmWfo378/S5cujVK0De+ii4Kkp4fYvLlhyiPCtORkSl98kaOzZqFs3UrroUOxrVwJmtagryOEaFrGTISDQUyVlZSRCiA1wkIIccz+/ftJT0+nTZs2WCwWBgwYwI4dO2q16dGjBwkJ+oxpt27d8Hg80Qi1USgKXHGFn/ffP79l1Op68spbbyXwv/9LoFs3HFOm4LzlFkw//tjALySEaCqGTITNx76SKjG1AmRGWAghwjweDy6XK3Lb5XKdNtHdvHkzvXv3borQmsyQIdWUlZn4/PPzW0atTr/4BSWrVlH26KPEf/QRrYcOJfH116V2WAgDqteZ5Zoby65dAOy19cRi0UhJka+mhBDibG3bto0DBw4wc+bMU96/adMmNm3aBMCcOXNwu931el6LxVLvto0hJwdyczU++sjBVVc1/AmXLBYL7jZtIC+P4A03YLnrLtLy8rCvXUto3jw0g3+wiPb+a2zSv2ZCVcHng7IylNJS8HigtBSlrAzKysDrRfH59DZer76ed3k5jBmDe8qUBgvDkIlw3K5daIrCLlMPnE4VRYl2REII0Tw4nU5KSkoit0tKSnA6nSe1+/LLL1m9ejUzZ84kLi7ulM+VnZ1NdnZ25HZxcXG9YnC73fVu21j69XPx1lsmJk8ubvD3iFr9s9th6VJsK1Zgf+IJLP37U3nTTfhycwl16tSwL9xEmsP+a0zSvwaiaSiVlShlZZjKyzGVl6McS15N4Z8+H0p5OabSUv1y9Gjkp1JejnKGb1FUmw0tKQktKYlQSgpaSgpms/mc+teuXbtTbjdmIrx7N6HOnTnsTZX6YCGEOEFGRgaFhYUUFRXhdDrZvn07kydPrtXm4MGDLFmyhGnTppGamhqlSBvX6NFVTJuWxp49Fn75y4YuFv4ZRaFq3Dj8o0aRMncuSa+8QtLSpdRkZVF53XVU/frXaHZ748YgxNlSVT1JLSuLJKbhZNZ0QkJrOnoU5ehRvZ3Xi1JRcbztGQrxNUVBS05GdTj0S1oawU6d0NLSUFNTUe12NLsdNS1Nv6SmoqWmoqakoCUng9l80nO63W5owETfsIlwIDMTzxGTrCEshBAnMJvN3HbbbcyaNQtVVRkyZAgXXHABK1asICMjg6ysLJYuXYrf7+fZZ58F9DeWBx98MMqRN6yrrvLz8MMa77xj45e/9DbJa2qpqZQ/9hi+3/+exNWrsa1aRdq0adgff5yq666j8uabCfTogXyNKRpEeEa2vFyfaS0p0S+aRlJREUplpT776vFg8nhQKiowVVToP8vKUMrKUM6w6olqtepJq8OBmppKqF27SJKqpqYeT1zDCW34vqQkNLsdLTERTM37cDTDJcKK14vl+++pvOEGSlaZ+NWvGvmTvhBCGEyfPn3o06dPrW1jx46NXJ8xY0ZTh9TkWrVS6d+/hnXrrNx/v7dJc0+1fXt899yD7+67idu5k6TXXiPxzTdJWrqUYKdO+EeOxD9iBDWXXgoWw70Ni4aiqsdnV32+4yUFZWV6AhuedS0rw+TxYC4uxlRSoie/4Uvo1DXw4e951KQkVJcL1elES04m6HBEkljtWCIbno2NJLJ2O2pysj4jW0fZVCwx3H9g3DffAOgzwktMUhohhBDilMaMqeKhh9L49ltLdCZNFIXAJZdw9JJLKHvkEWzr12Ndv56kv/yF5MWLUe12qgcOpHrgQGr69yfYrVuznz0TJwgG9bIBr/d4LWy4BrasLFJ2ECk1qKjQE9sT62nPMCOrWa2odjuq04nqdlPTsydacjKa1YqWmBhJXtXUVFS3G9XlIu3CCympqtJnY1tAInu+DJcIh1eMqP5VJkePmmTpNCGEEKd01VV+pk/XyyN+9aumKY+oi+ZwUHnjjVTeeCNKeTkJ779PwpYtWLdswfa3vwEQcjgIXHopNZdeSk3v3gS7dUNNT5dSisYQCtWuiS0rO14rG75eXo5SUaG3DQb1RPbEg76OHj3tS2hxcXrJQEpKZIY12KGDnryeWEoQnoENt0tL05Nfux1strPvm9uNFsMHAzY0wyXCcbt3E3I48FjboWmKJMJCCCFOye1WuewyvTzigQeatjzidDS7Hf/VV+O/+mrKNA3zDz8Q/8knJHzyCXGffYb92JJ1AGpiIqHOnQl27kzwwguPX+/cWU+SW8oMcnV1ZJZVqanRL4EAHPuplJfrtbDhJDVcYhBObn0+/cCuUAiT30+78vLTvpxmNuvJalISWCxoFguazYbqcBDs2FGfoXU6I0lrOIkNHxCmORxoVqt8iDEA4yXCu3YRzMykxKMfSSiJsBBCiLqMGVNFXl4a33xj4aKLmuExJYpCqHNnqjp3pupYHbdy9ChxX32F5cCB45c9e7Bu3Kgnf8doFguh9HRCbdvqSVlqKqrDQahDB4IdOqC6XPoBVZqmf8V+7Mh9Lf74iUYUvx+lqgolEECLj9eTN7tdX+P1VEm2qkIgoCd4x5I8JRCA6mr94KxjqwugqvrX91arnrT6fJgqK/XX8vv1+tZwyUC4bMDn0xPbYFAvOwivWFBWhqmyst6/UjU5+fiMa2oqwY4d9YQ2Lg7NYsGalkZlQoI+65qaery8IFwrm5amlxVIEtsiGCsRDgaJ+/ZbKm69FY9H/wd1Oht+sXQhhBCxIVwesWaNjYsuim55RH1paWnUDBpEzaBBte8IBjEfPoz5+++xfP895h9/1G8XFmI5dAilrAyzx4Pi9593DO0AzWTSl69SFD0pDgbPuFzW2VKtVr3mNTlZXy/WakWzWMBs1hPYiy/W61/DM60pKWgJCXoyHx+PFhcHcXF6IutyoaalnbEuNs7txiulA+IYQyXClgMHUKqr9QPlIomwzAgLIYQ4NZdLZdgwP2++mcgf/uA19iINFguhjh0JdexIzeDBp26jaZhKSjAXFGAqLdUTWEVBqaqK1LcSCMCxg7Q0qxXNZoP4eH1W1+8nyWKhsrxcn+lVVb2tpoHZrCeg4V/isZMhaAkJ+myrzRZZCxazWZ/59fv1mebwklo2W+Q1tZQUOZhLRJ2hhoS4YwfKBTIz8XwmibAQQogzGzu2ir//3cbWrQlkZ1dHO5zGpSj66gHncYpdm9uNT2ZMRQthqCr7uF270OLjCWZkUFIiibAQQogzGzbMj9sdYsWKxGiHIoRoZgyVCFt27SLwi19AXBwej4mkJBWrNdpRCSGEaM7i4uDf/72Kv//dGplEEUIIMFgibCotJZCZCYDHI2sICyGEqJ+xYysJBhVWrTqHdVmFEDHLUDXCxe++qxf5A6WlkggLIYSon1/8Isgll9Tw178mMmFChayMJYQADDYjDESOMC0pkURYCCFE/Y0bV8mePXF89pmsVCCE0BkvET5GSiOEEEKcjZycKlJTVf785+RohyKEaCYkERZCCNEiJCdr3HxzBevXWzl0yBztcIQQzYAhE2G/HyoqTDgckggLIYSov//4jwpMJnjppaRohyKEaAYMmQh7vXrYqamSCAshhKi/tm1VcnKqWL48kaNH5Yg5IVo6QybCPp8+eKWkaFGORAghhNHceaePykoTS5fKrLAQLZ1BE2E97JQUmREWQghxdjIzgwwaVM1f/pKE3x/taIQQ0WTIRNjr1WeEk5NlRlgIIcTZu+ceLz/9ZGb5cjntshAtmSET4XBphCTCQgghzsX/+381XHZZNQsWpFBVFe1ohBDRYshEOHywXHKylEYIIYQ4e4oC99+vzwq/9prUCgvRUhk0EZaD5YQQQpyf/v1rGDSomoULk6mokBUkhGiJDJkIV1TIjLAQQojz98AD5ZSUmHnlFZkVFqIlMmQi7PUqWCwaVmu0IxFCCGFkl14aYNgwPy+8kMyRI4Z8SxRCnAdD/tf7fArJyRqKfJMlhBDiPD3ySBlVVQqzZtmjHYoQookZMhH2ek1SFiGEEKJBdO0a4ve/97FyZSL/+7/x0Q5HCNGEDJkI+3yKHCgnhBCiwdx7r4/27YNMm5ZKMBjtaIQQTcWQibDMCAshRN127tzJvffey6RJk1izZs1J9+/evZsHH3yQcePG8fHHH0chwuYnMVHj0UfL+eabOPLz5cA5IVoKQybCMiMshBCnpqoq+fn5TJs2jXnz5vHhhx/yr3/9q1Ybt9tNbm4uAwcOjFKUzdPIkX6ys/089ZSdffss0Q5HCNEEDJsIy1nlhBDiZPv37yc9PZ02bdpgsVgYMGAAO3bsqNWmdevWdOrUCUWOOK5FUeDpp49is6lMnpxGIBDtiIQQjc2gibCJlBQpjRBCiJ/zeDy4XK7IbZfLhcfjiWJExtK6tcpTT5Xx5ZfxzJ+fEu1whBCNrF7f/ezcuZOXX34ZVVUZNmwYOTk5J7XZvn07K1euRFEUOnXqxL333tvgwYZ5vTIjLIQQjW3Tpk1s2rQJgDlz5uB2u+v1OIvFUu+2zdEtt8C2bSGefz6ZnBwrl11W+/3G6P07E+mfsUn/zvL5ztQgXG/28MMP43K5eOihh8jKyqJDhw6RNoWFhaxZs4Y//elPJCcnU1ZW1mAB/lwoBJWVcrCcEEKcitPppKSkJHK7pKQEp9N5Ts+VnZ1NdnZ25HZxcXG9Hud2u+vdtrmaNk3hvfdaMW6cib///Qgu1/H3nFjo3+lI/4xN+ndq7dq1O+X2M5ZG1Kfe7B//+AcjRowgOTkZgNTU1LMOsL58Pr2mTWaEhRDiZBkZGRQWFlJUVEQwGGT79u1kZWVFOyzDsds1lizxUFpqIjfXQSgU7YiEEI3hjIlwferNDh8+TGFhITNmzGD69Ons3Lmz4SM9xufTQ5ZVI4QQ4mRms5nbbruNWbNmMXXqVC677DIuuOACVqxYwaeffgroExwTJ07k448/5s9//jP33XdflKNunnr0CPLEE0f54IMEnn5a6oWFiEUNsj6MqqoUFhbyxz/+EY/Hwx//+EeeeeYZkpJqr8XYEPVmRUX6jHC7dkm43YkNEX7UST2PsUn/jC0W+9enTx/69OlTa9vYsWMj17t27cqiRYuaOixDGjeuis8+i2fBghR+8Ysgv/51VbRDEkI0oDMmwvWpN3M6nXTr1g2LxULr1q1p27YthYWFdO3atVa7hqg3O3QoDmiFppVTXFxdr8c3d1LPY2zSP2M7l/7VVWsmYtOf/lTGwYMWpkxJIzVV5YYboh2REKKhnLE0oj71Zv/2b//Grl27ACgvL6ewsJA2bdo0SsDh0gg5WE4IIURTsFrh5Zc9/PKXASZMcPDRR7L+shCx4owzwifWm6mqypAhQyL1ZhkZGWRlZdGrVy+++OILpk6dislk4uabbyYlpXHqqbxefQCSGmEhhBBNJSVFY9kyDzk5bq691sJ//3ccvXvLGTeEMLp61Qifqd5MURTGjx/P+PHjGza6Uzg+IyyJsBBCiKbjdqv89a8ljB3bmnHjXCxdWkJWliTDQhiZ4c4sF54RltIIIYQQTa1DhxCbNgVwuVRuvNHFJ5/ERzskIcR5aJBVI5pSRYWsIywaj6Zp+P1+VFVFUepXB/jTTz9RXR0bB26eSkvtn6ZpmEwmrFZrvf8WRMtwwQWwalUxN9zg4sYbXcyfX8qYMf5ohyWEOAeGS4S9XhOJiSpmc7QjEbHI7/cTFxeHxVL/fw2LxYI5hv8gW3L/gsEgfr8fm83WxFGJ5i49XWXNmhL+4z+cTJzo5NChcnJzfchnJiGMxXClET6fIgfKiUajqupZJcEitlksFlRVyrDEqTmdKitWFHPNNVU88YSdKVPSqKyUTFgIIzFcIuz1mqQ+WDQa+Qpc/Jz8TYjTsVph4cJS/vM/y1m1ysbo0W727ZMP00IYheESYZ9PkfpgEZM8Hg/Dhw9n+PDh9O7dm0svvTRyu6am5rSP/eKLL5gxY8YZX+Oaa65pqHCFEMeYTHDffT7++79LKCkxMWqUm6VLE9HkrUqIZs9wH1u9XkmERWxyOp1s3LgRgLlz55KUlMTEiRMj9weDwTrLNnr16kWvXr3O+Bpr165tmGCbUCgUiukaZRE7Bg+uYcOGI9x7r4MHH0zjb3+z8vTTR2nfXr7FFKK5Mlwi7POZ6NQpGO0whGgSU6ZMISEhgV27dpGVlcW1117LI488QnV1NVarlWeffZauXbuyfft2Fi1axGuvvcbcuXP58ccfOXToED/++CN33HEHt99+OwDdunVj3759bN++nWeffRaHw8GePXvo2bMnCxYsQFEU/vGPf/Doo4+SmJhI3759OXToEK+++mqtuAoKCpg8eTKVlZUAPP744/Tt2xeAhQsX8tZbb6EoCkOHDmXatGkcPHiQvLw8SkpKMJvNLF68mMOHD0diBpg+fTo9e/Zk7Nix9OvXj2uuuYZt27aRm5uLz+dj2bJl1NTUcOGFF/L8889js9k4cuQIeXl5/PDDDwDMnj2brVu3kpaWxoQJEwCYM2cObrebO+64o0n2mWjZ0tNVli8v4bXXEnn8cTvDhrXmP//Ty623VhAXF+3ohBA/Z8BEWGaERdN45BE7u3ef+Z1LURS0en4HetFFAR57rPys4igsLOTtt9/GbDbj9XpZvXo1FouFbdu28eSTT7JkyZKTHrN//35WrlxJRUUFgwYN4pZbbiHuZ+/CX3/9NZs3byY9PZ1rr72WHTt20LNnTx588EHeeustOnbsSG5u7iljcrvdLF++HKvVyoEDB7j77rtZv349mzdvZsOGDaxbtw6bzUZpaSkAkyZN4u6772bUqFH4/X40TePw4cOn7bfD4WDDhg2AXjZy0003AfDkk0+yfPlybrvtNmbMmEH//v3Jz88nFApRUVFBeno6d9xxBxMmTEBVVdauXcu6devO6ncuxPkwmeDWWysZMqSahx5KZebMVJYvT+TRR8sYNOj0ZU5CiKZluETY6zWRkiJfM4mWY/To0ZHSgPLycqZMmcLBgwdRFIVA4NRntRo2bBgJCQkkJCTgdrs5cuQI7dq1q9Wmd+/ekW2ZmZkUFBSQmJhIp06d6NixIwA5OTksW7bspOcPBAJMnz6d3bt3YzKZOHDgAADvv/8+Y8eOjSw35nA48Pl8FBYWMmrUKACsVmu9+n1iPfOePXt46qmnKC8vp6KigssvvxyADz/8kOeeew7QTwdvt9ux2+04HA6+/vprjhw5QmZmJk6ns16vKURD6tQpxLJlHjZuTGDmzFTGjXMzeLCfvDwvvXrJGemEaA4MlQhrmswIi6ZT35lbi8VCMNh45TqJiYmR608//TQDBgwgPz+fgoICfvOb35zyMQkJCZHrZrOZUCh0Upv4+Phabc6mD0uWLKFVq1Zs3LgRVVXp0qVLvR8bZrFYas2k//ykFif2e+rUqeTn55OZmcmKFSv46KOPTvvcv/3tb3njjTcoKipi3LhxZx2bEA1FUeDKK6sZPLiI115LYsGCZK66qhUjRlQxaZKPSy6RhFiIaDLUqhF+PwSDso6waLm8Xi/p6ekAvPHGGw3+/BkZGfzwww8UFBQAdR9cV15eTuvWrTGZTKxatSqSaA8ePJgVK1ZQVVUFQGlpKcnJybRt25Z3330X0BPeqqoq2rdvz969e6murqasrIwPPvigzrh8Ph9t2rQhEAiwevXqyPaBAwdGaoxDoRDl5fqHl1GjRrFlyxa++OILrrjiivP7pQjRAKxWuPPOCrZvL+L++8v55JMERo9uxfXXu/jHPxKQ5aqFiA5DJcI+nx5uUpKMGKJluuuuu5g9ezZXXnllo8xC22w2nnjiCW666SZGjhxJUlISdrv9pHbjx4/nzTffJDs7m/3790dmb4cMGcKVV17JqFGjGD58OIsWLQLg+eefJz8/n+zsbK699lqKiopo3749Y8aMYejQoUycOJEePXrUGdcDDzzA6NGjycnJoWvXrpHtjz32GNu3b2fYsGGMHDmSvXv3Avps94ABAxgzZoysOCGalZQUjalTfXzyyU/MmFHGgQMWbrnFxaBBrXnppSSOHpV1q4VoSopW36N8GsGZDpYJc7vdFBcXc+CAmUGD2vD886X8+79XNXJ0TSfcv1hlpP5VVlbW+kq+Phq7NKKpVVRUkJSUhKZpTJs2jYyMDMOtuKCqKiNGjGDx4sVnLNs40/471d/Ez+utW4qzHbNjVUP2r6YG/vY3G/n5SXz+eTwJCRojRvgZO7aSgQOricaJLmX/GZv079TqGrcNVSNcUaHPCMvBckI0nmXLlrFy5UoCgQA9evTglltuiXZIZ2Xv3r2MHz+ekSNHnlPtshBNKT4ecnKqyMmp4quv4lixwsbq1YmsXWvD5Qpx1VV+Ro+uol+/Gll+TYhGYKhE2OvVvzKSg+WEaDx33nknd955Z+S20Wa8u3fvfsaD6YRoji6+OMDFFweYMaOczZutrF1r4803bbz+ehKpqSpDh/rJzq5m8OBqnE6ZEBKiIRgqEfb59ERYDpYTQggRqxISYNQoP6NG+amsVHjvvQT+/ncrmzYlsHp1Ioqi0bt3gIEDqxkwoIa+fWuw2eR9UYhzYahE2OvVSyOSk+WTsBBCiNiXmKhFkuJQCL78Mo6tWxPYssXKiy8ms2CBQlycRo8eAS69tIasrBp69w7QoUMIRY67E+KMDJYIS2mEEEKIlslshksuCXDJJQGmTvVRUaGwY0c8H30Uz6efxrN0aRIvvZQMgMsVolevAJmZAXr0CPCrXwXo3DmELKIiRG2GSoTDy6fJjLAQQoiWLilJ44orqrniCv1kNDU18M03cezcGcfOnfF89VUc772XQCikTyIlJGhkZATp3j1A165BunUL0qVLkM6dQyQmygSTaJkMlggrWCwa9TxDqxCG85vf/IZ77rmn1kkglixZwnfffcecOXPqfMyMGTPo1asXv/vd73jhhRdITU2t1Wbu3LkkJSUxceLEOl/73XffpUuXLnTv3h3Qz2LXr18/hg4dev4dE0I0uvh46NUrQK9eAcaPrwT0E1Ht2RPHt99a2Ls3jr17LXz2WTxr1tReEjA9PUTHjkE6dgzxy1+acTptXHBBiPbtQ6SnhzjhZJVCxBTDJcLJyZrUPYmYlZOTw9tvv10rEX777bd5+OGH6/X4119//Zxf+9133yU7OzuSCD/wwAPn/FzREgqF5AQaQpzAaj2eHMPx9ferqhS++87MgQMWvv/ewsGDFgoKzGzfHs+qVSY0zVHreVyuEG3bhkhPV0lPD9GmTYjWrVVatVJxu0PHfqoysywMx1CJsNdrkjWERUy7+uqreeqpp6ipqSE+Pp6CggJ++ukn+vXrR15eHl988QV+v5+rr76a+++//6TH9+tCEyWyAAAQ1klEQVTXj/Xr1+N0OnnuuedYuXIlbrebdu3a0bNnT0BfJ3jZsmXU1NRw4YUX8vzzz/P111+zceNGPv74Y5577jmWLFnC/Pnzyc7OJicnh/fff58//elPhEIhevXqxezZs0lISKBfv35cf/31bNy4kWAwyOLFi2ud+Q2goKCAyZMnU1mpz1A9/vjj9O3bF4CFCxfy1ltvoSgKQ4cOZdq0aRw8eJC8vDxKSkowm80sXryYw4cPs2jRosjplKdPn07Pnj0ZO3Ys/fr145prrmHbtm3k5ubi8/lO6p/NZuPIkSPk5eXxww8/ADB79my2bt2K0+nk9ttvB2DOnDm43W7DnUBEiLNls2n06BGkR4+Tl0a02918+WUpBQVmDh/WL4WF+uXwYTOffx6Hx3PqD5xWq4rTefzicKg4HBppafr11FSVtDSVtDQNu10lJUXFbtdISpJJLhEdhkqEwzPCQjQF+yOPELd79xnbKYpCfU/QGLjoIsofe6zO+x0OB71792bLli2MGDGCt99+mzFjxqAoCg8++CAOh4NQKMTYsWPZvXs3F1100Smf58svv2Tt2rWRBHXkyJGRRHjUqFHcdNNNADz55JMsX76c2267jeHDh5Odnc3o0aNrPZff72fq1KmsWLGCjIwMJk+ezGuvvcaECRMAcDqdbNiwgVdeeYVFixbxzDPP1Hq82+1m+fLlWK1WDhw4wN1338369evZvHkzGzZsYN26ddhsNkpLSwGYNGkSd999N6NGjcLv96Np2hnPaOZwONiwYQMAHo/nlP2bMWMG/fv3Jz8/n1AoREVFBenp6UyYMIHbb78dVVVZu3Yt69atO+1rGcHOnTt5+eWXUVWVYcOGkZOTU+v+QCDACy+8wIEDB0hJSWHKlCm0bt06StGK5iY+Hjp3DtG5c6jONoEAFBebKCoyU1xsorjYREmJmZIS/XppqQmPx8ShQxaOHjVRVqagaXVnuiaTRkqKRkqKSkqKnhgnJ6skJ+s/k5L0bYmJJ15UbLbjt2224xerVb/ExyMJtjgtQyXCMiMsWoJweUQ4EZ47dy4A77zzDsuWLSMUCvHTTz+xb9++OhPhTz75hJEjR2Kz2QAYPnx45L49e/bw1FNPUV5eTkVFBZdffvlp4/nuu+/o2LEjGRkZAFx//fW8+uqrkUR41KhRAPTs2ZP169ef9PhAIMD06dPZvXs3JpOJAwcOAPD+++8zduzYSIwOhwOfz0dhYWHkOa31PCDgmmuuOWP/PvzwQ5577jkAzGYzdrsdu92Ow+Hg66+/5siRI2RmZuJ0Ouv1ms2Vqqrk5+fz8MMP43K5eOihh8jKyqJDhw6RNps3byYpKYkFCxbw4YcfsmzZMqZOnRrFqIXRxMVB27YqbdvW7z05FIKyMoWyMtMJF4XyctOxi4LXa8LrVaio0K8fPWriX/9S8PlMVFbq28MH/tWXohxPihMSwGrVSEoyYbG4SUjQtyUkaMTHa8d+Qlzc8evx8dqx2/r2uLjjbfT7wGKp/0+L5cSfx69Lsh49hkqEfT4Fl0sSYdE0Tjdze6KGPvPaiBEjmDlzJl999RVVVVX07NmTQ4cOsXjxYv7nf/6HtLQ0pkyZgt/vP6fnnzp1Kvn5+WRmZrJixYrzPgtbwrGjaMxmM6HQyTNIS5YsoVWrVmzcuBFVVc/ptMcWi6XWrHt1dXWt+xMTjx/4c7b9u+mmm3jjjTcoKipi3LhxZx1bc7N//37S09Np06YNAAMGDGDHjh21EuFPP/2U66+/HoD+/fvzl7/8BU3TUOTdWDQSsxmcTg2nMwTUPdN8OpoG1dVQWalQWWk69lO/+P0KVVW1r1dVKVRX67f9foXqaqiuVlBVK16vGmlXVqa3q65WqKmBmholcqmu5rQz2Q3FZNIT4vBPiwXMZg2zmWOX8P168mw269fDbU68brVaUFUnJtPJbcK3w9dPddtk0m8rSvj+49tO3P7zduFtinL6bcd/ntxWv66P9eH7fv64nj0V2rZtuN+9oRJhr9dEp07n9g8khFEkJSUxYMAA7rvvvshX2l6vF5vNht1u58iRI2zZsoXLLruszufo378/U6dO5Z577iEUCrFx40Z+97vfAeDz+WjTpg2BQIDVq1eTnp4OQHJyMhUVFSc9V0ZGBgUFBRw8eJALL7yQVatW0b9//3r3p7y8nLZt22IymVi5cmUkWR48eDDz5s3juuuui5RGOBwO2rZty7vvvsvIkSOprq5GVVXat2/P3r17qa6uxu/388EHH0TqjH+urv4NHDgwUtIRLo2w2+1cddVVPPnkkwSDQRYuXFjvfjVXHo8Hl8sVue1yudi3b1+dbcxmM4mJiXi9Xux2e5PGKsTZUBT94D+rNZxQnxu3201xsadebTVNn83WE2MIBPQEORCAYFDfFgzqtwOB49vDt4NB/XYwePx2KKTfHwodvz8U0l8nEDh+PRQ6+Xq4rarWvn5iW78fqqtNx7aDqiqR6+Hn0jROuv/45ef36x8GQiEi25viw0FdJkwIMXNmwz2foRLhl1/2YLFIjbCIfTk5Odx+++3813/9FwCZmZn06NGDwYMH065duzqTwLCLL76YMWPGMHz4cNxuN717947c98ADDzB69GhcLheXXHIJPp8PgGuvvZYHHniA/Px8/vznP0faW61Wnn32WX7/+99HDpYLJ9X1MX78eO68807efPNNhgwZEpm9HTJkCLt27WLUqFHExcUxdOhQHnroIZ5//nkefPBBnnnmGSwWC4sXL6ZTp06MGTOGoUOH0rFjR3r06FHn69XVv8cee4w//OEP/PWvf8VkMjF79myysrKIj49nwIABpKamyooTP7Np0yY2bdoEHD+QsD4sFku92xqR9M/YYr9/UPtLyp/nTeefR52YKGva8Q8M4e16sly7zc+3hx934rYTt2uaclIbTYPWrc0Nuv8Urb5H+TSCMx0AE6Z/eitu5GiiR/rXfFRWVtb6mr0+Gro0ormJ9f6ZTCaGDRvG4sWLT1m2caq/iXbt2jVVeGdt7969rFy5kunTpwOwevVqAH79619H2syaNYvrr7+e7t27EwqFuPPOO3nppZfOWBohY7ZO+mds0j9jO9f+1TVum843ICGEMKq9e/fSr18/Bg4ceE61y81RRkYGhYWFFBUVEQwG2b59O1lZWbXaXHrppWzduhWAjz/+mMzMTKkPFkK0SIYqjRBCiIbUvXt3duzYEVMz3mazmdtuu41Zs2ahqipDhgzhggsuiCx/l5WVxdChQ3nhhReYNGkSycnJTJkyJdphCyFEVEgiLIQQMaZPnz706dOn1raxY8dGrsfHx3Pfffc1dVhCCNHsSGmEECeIYsm8aKbkb0IIIWKXJMJCnMBkMsXU1+Ti/ASDQUwmGSaFECJWSWmEECewWq34/X6qq6vrffBQQkLCSSd4iCUttX+apmEymep9djshhBDGI4mwECdQFCVyyt/6kqVqjC3W+yeEEKJu8p2fEEIIIYRokSQRFkIIIYQQLZIkwkIIIYQQokWK6imWhRBCCCGEiBZDzAjn5eVFO4RGJf0zNumfscV6/6Ih1n+n0j9jk/4ZW0P3zxCJsBBCCCGEEA1NEmEhhBBCCNEimWfOnDkz2kHUR5cuXaIdQqOS/hmb9M/YYr1/0RDrv1Ppn7FJ/4ytIfsnB8sJIYQQQogWSUojhBBCCCFEi9TsT7G8c+dOXn75ZVRVZdiwYeTk5EQ7pHNWXFzMwoULOXr0KIqikJ2dzVVXXYXP52PevHkcOXKEVq1aMXXqVJKTk6Md7jlTVZW8vDycTid5eXkUFRUxf/58vF4vXbp0YdKkSVgszf5P75QqKipYtGgRBQUFKIrCXXfdRbt27WJm/61bt47NmzejKAoXXHABubm5HD161LD778UXX+Tzzz8nNTWVuXPnAtT5/6ZpGi+//DL//Oc/SUhIIDc3N+a/XmwMsTRmQ8sYt2XMNu6+i7UxG6IwbmvNWCgU0u655x7t//7v/7RAIKDdf//9WkFBQbTDOmcej0f77rvvNE3TtMrKSm3y5MlaQUGB9vrrr2urV6/WNE3TVq9erb3++uvRDPO8vfPOO9r8+fO12bNna5qmaXPnztU++OADTdM0bfHixdqGDRuiGd55WbBggbZp0yZN0zQtEAhoPp8vZvZfSUmJlpubq1VXV2uapu+3LVu2GHr/7dq1S/vuu++0++67L7Ktrv312WefabNmzdJUVdX27NmjPfTQQ1GJ2chibczWtJYxbsuYbcx9F4tjtqY1/bjdrEsj9u/fT3p6Om3atMFisTBgwAB27NgR7bDOmcPhiHxSsdlstG/fHo/Hw44dO7j88ssBuPzyyw3dx5KSEj7//HOGDRsGgKZp7Nq1i/79+wNwxRVXGLZ/lZWVfPPNNwwdOhQAi8VCUlJSTO0/VVWpqakhFApRU1NDWlqaofffRRdddNJMT13769NPP2Xw4MEoikL37t2pqKigtLS0yWM2slgbsyH2x20Zs4277yD2xmxo+nG7Wc+VezweXC5X5LbL5WLfvn1RjKjhFBUVcfDgQbp27UpZWRkOhwOAtLQ0ysrKohzduXvllVe4+eabqaqqAsDr9ZKYmIjZbAbA6XTi8XiiGeI5Kyoqwm638+KLL/LDDz/QpUsXbr311pjZf06nkzFjxnDXXXcRHx9Pr1696NKlS8zsv7C69pfH48HtdkfauVwuPB5PpK04s1gesyE2x20Zs42771rKmA2NO2436xnhWOX3+5k7dy633noriYmJte5TFAVFUaIU2fn57LPPSE1Njdm6ylAoxMGDB7nyyit56qmnSEhIYM2aNbXaGHn/+Xw+duzYwcKFC1m8eDF+v5+dO3dGO6xGZeT9JZpWLI7bMmYbd99ByxyzoeH3WbOeEXY6nZSUlERul5SU4HQ6oxjR+QsGg8ydO5dBgwbRr18/AFJTUyktLcXhcFBaWordbo9ylOdmz549fPrpp/zzn/+kpqaGqqoqXnnlFSorKwmFQpjNZjwej2H3ocvlwuVy0a1bNwD69+/PmjVrYmb/ffXVV7Ru3ToSf79+/dizZ0/M7L+wuvaX0+mkuLg40i4WxpumFotjNsTuuC1jtnH3HbScMRsad9xu1jPCGRkZFBYWUlRURDAYZPv27WRlZUU7rHOmaRqLFi2iffv2jB49OrI9KyuL9957D4D33nuPvn37RivE83LjjTeyaNEiFi5cyJQpU+jRoweTJ08mMzOTjz/+GICtW7cadh+mpaXhcrk4fPgwoA9CHTp0iJn953a72bdvH9XV1WiaFulfrOy/sLr2V1ZWFtu2bUPTNPbu3UtiYqKURZylWBuzIbbHbRmzjbvvoOWM2dC443azP6HG559/zquvvoqqqgwZMoTrrrsu2iGds2+//ZZHHnmEjh07Rqb1f/vb39KtWzfmzZtHcXGx4ZdyCdu1axfvvPMOeXl5/PTTT8yfPx+fz8eFF17IpEmTiIuLi3aI5+T7779n0aJFBINBWrduTW5uLpqmxcz+e+ONN9i+fTtms5nOnTszceJEPB6PYfff/Pnz2b17N16vl9TUVG644Qb69u17yv2laRr5+fl88cUXxMfHk5ubS0ZGRrS7YDixNGZDyxm3Zcw25r6LtTEbmn7cbvaJsBBCCCGEEI2hWZdGCCGEEEII0VgkERZCCCGEEC2SJMJCCCGEEKJFkkRYCCGEEEK0SJIICyGEEEKIFkkSYSGEEEII0SJJIiyEEEIIIVokSYSFEEIIIUSL9P8BrEfQCbvhh/sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with Model"
      ],
      "metadata": {
        "id": "UQdJvehPJzl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tryit(utterance):\n",
        "  # transform our utterance as we did both the train and test set\n",
        "  vect = vectorizer.transform([utterance])\n",
        "  print(model.predict(vect)[0])"
      ],
      "metadata": {
        "id": "ZmWsz3XeJyJs"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\" I'm never going back.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSmf0K7KWyc",
        "outputId": "4a7a7c84-97ee-479f-f2d6-b4b5ca87d411"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 85ms/step\n",
            "[0.00063037]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\"I love this place!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spIvqpRBb_R7",
        "outputId": "80ad4d9a-fd97-43c3-ee2c-454df8a2d3b0"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 11ms/step\n",
            "[0.9999314]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\" Wish there were more options for food.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_rnMS7C8wfe",
        "outputId": "5eb9e1fe-54ae-4f29-8fa9-0409be15d3cb"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 11ms/step\n",
            "[0.35003114]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\"This is a perfect place to waste your time.\") # still can't understand sarcasm :("
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCMKz85981i8",
        "outputId": "0385e413-c5ac-48f0-e859-b93bb6b33ae4"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "[0.9993792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\" JC Penny is so dated\") # not sure about whether people like JC Penny's"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVUJQKam8-h5",
        "outputId": "e8b434de-f594-43a6-91ef-073a6d33d4f4"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 12ms/step\n",
            "[0.5030221]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit( \"Poor customer service in Belk's\") # understands someone doesn't like Belk's"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCC46YNn9HXA",
        "outputId": "c922e1ce-1de8-4a46-959a-a515aa6be1e8"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "[0.00079495]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tryit(\" This place should be torn down.\") # still thinks tearing the mall down is a positive sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAU6owBl9Su_",
        "outputId": "c83dfc7e-32fd-47fb-e32d-0dc018428a8a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 11ms/step\n",
            "[0.9005569]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall I'm prety satisfied with my understanding of Keras. I think I am also beginning to understand that the largest hurdle for A.I. and NLP is clean standardized data. "
      ],
      "metadata": {
        "id": "d_0sygJp9bEk"
      }
    }
  ]
}